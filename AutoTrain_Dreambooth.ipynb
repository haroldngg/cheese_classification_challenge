{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JvMRbVLEJlZT",
        "outputId": "85c11987-9746-49b2-c6a8-465b157319e3"
      },
      "outputs": [],
      "source": [
        "#@title ðŸ¤— AutoTrain DreamBooth\n",
        "#@markdown In order to use this colab\n",
        "#@markdown - upload images to a folder named `images/`\n",
        "#@markdown - choose a project name if you wish\n",
        "#@markdown - change model if you wish, you can also select sd2/2.1 or sd1.5\n",
        "#@markdown - update prompt and remember it. choose keywords that don't usually appear in dictionaries\n",
        "#@markdown - add huggingface information (token) if you wish to push trained model to huggingface hub\n",
        "#@markdown - update hyperparameters if you wish\n",
        "#@markdown - click `Runtime > Run all` or run each cell individually\n",
        "#@markdown - report issues / feature requests here: https://github.com/huggingface/autotrain-advanced/issues\n",
        "\n",
        "import os\n",
        "!pip install -U autotrain-advanced > install_logs.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7.94\n"
          ]
        }
      ],
      "source": [
        "!autotrain --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu May 16 18:35:33 2024       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.78                 Driver Version: 550.78         CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA RTX A5000               Off |   00000000:01:00.0 Off |                  Off |\n",
            "| 30%   38C    P8             23W /  230W |     122MiB /  24564MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A    284829      G   /usr/libexec/Xorg                              94MiB |\n",
            "|    0   N/A  N/A    284855      G   /usr/bin/gnome-shell                           19MiB |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "noam-joud-harold.ngoupeyou pts/0        2024-05-16 18:31 (129.104.231.189)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "!who"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 14:44:54\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m388\u001b[0m - \u001b[1mRunning DreamBooth Training\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-16 14:44:54\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[33m\u001b[1mParameters not supplied by user and set to default: vae_model\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-16 14:44:54\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: inference, config, valid_split, train, train_split, version, data_path, deploy, log, func, backend\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 14:44:54\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 14:44:54\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mcheddar/000013.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 14:44:54\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 14:44:54\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mcheddar/000020 - Copie.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 14:44:54\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 14:44:54\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mcheddar/000020.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 14:44:54\u001b[0m | \u001b[36mautotrain.backends.local\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 14:44:54\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m360\u001b[0m - \u001b[1m['python', '-m', 'autotrain.trainers.dreambooth', '--training_config', 'cheddargrated/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 14:44:54\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m361\u001b[0m - \u001b[1m{'model': 'stabilityai/stable-diffusion-xl-base-1.0', 'vae_model': None, 'revision': None, 'tokenizer': None, 'image_path': 'cheddargrated/autotrain-data', 'class_image_path': None, 'prompt': 'An image of a grated cheddar cheese', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'cheddargrated', 'seed': 42, 'resolution': 1024, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 1, 'num_steps': 500, 'checkpointing_steps': 100000, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'disable_gradient_checkpointing': False, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': False, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': True, 'mixed_precision': 'fp16', 'token': '*****', 'push_to_hub': True, 'username': 'haroldng', 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-16 14:44:56\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[33m\u001b[1mFailed to download dataset: 404 Client Error. (Request ID: Root=1-6645ffc8-577481667201ec805e8e4bb2;89fe2fe7-6978-4427-9e72-5c383d7cce34)\n",
            "\n",
            "Repository Not Found for url: https://huggingface.co/api/datasets/cheddargrated/autotrain-data/revision/main.\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are authenticated.\u001b[0m\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "{'variance_type', 'dynamic_thresholding_ratio', 'rescale_betas_zero_snr', 'clip_sample_range', 'thresholding'} was not found in config. Values will be initialized to default values.\n",
            "{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "{'dropout', 'reverse_transformer_layers_per_block', 'attention_type'} was not found in config. Values will be initialized to default values.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 14:45:03\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m931\u001b[0m - \u001b[1m***** Running training *****\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 14:45:03\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1m  Num examples = 3\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 14:45:03\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m933\u001b[0m - \u001b[1m  Num batches each epoch = 3\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 14:45:03\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1m  Num Epochs = 500\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 14:45:03\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m935\u001b[0m - \u001b[1m  Instantaneous batch size per device = 1\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 14:45:03\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m936\u001b[0m - \u001b[1m  Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 14:45:03\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m937\u001b[0m - \u001b[1m  Gradient Accumulation steps = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 14:45:03\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m938\u001b[0m - \u001b[1m  Total optimization steps = 500\u001b[0m\n",
            "Steps:   0%|                                            | 0/500 [00:00<?, ?it/s]/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [25:34<00:00,  3.06s/it, loss=0.0811, lr=0.0001]\u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[32m2024-05-16 15:10:38\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mwrapper\u001b[0m:\u001b[36m120\u001b[0m - \u001b[31m\u001b[1mtrain has failed due to an exception: Traceback (most recent call last):\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/autotrain/trainers/common.py\", line 117, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/autotrain/trainers/dreambooth/__main__.py\", line 122, in train\n",
            "    main(_args)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/autotrain/trainers/dreambooth/train_xl.py\", line 1282, in main\n",
            "    unet = unet.to(torch.float32)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  [Previous line repeated 7 more times]\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 804, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "    return t.to(\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 50.00 MiB. GPU \n",
            "\u001b[0m\n",
            "\u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[32m2024-05-16 15:10:38\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mwrapper\u001b[0m:\u001b[36m121\u001b[0m - \u001b[31m\u001b[1mCUDA out of memory. Tried to allocate 50.00 MiB. GPU \u001b[0m\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [25:34<00:00,  3.07s/it, loss=0.0811, lr=0.0001]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 15:10:38\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m393\u001b[0m - \u001b[1mJob ID: 332559\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "project_name = 'cheddargrated' # @param {type:\"string\"}\n",
        "model_name = 'stabilityai/stable-diffusion-xl-base-1.0' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\n",
        "prompt = 'An image of a grated cheddar cheese' # @param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "hf_username = \"haroldng\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "num_steps = 500 #@param {type:\"number\"}\n",
        "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "gradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "resolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\n",
        "use_8bit_adam = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_xformers = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "mixed_precision = \"fp16\" # @param [\"fp16\", \"bf16\", \"none\"] {type:\"raw\"}\n",
        "train_text_encoder = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "disable_gradient_checkpointing = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"MIXED_PRECISION\"] = str(mixed_precision)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"DISABLE_GRADIENT_CHECKPOINTING\"] = str(disable_gradient_checkpointing)\n",
        "os.environ[\"HF_USERNAME\"] = hf_username\n",
        "\n",
        "\n",
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--image-path cheddar/ \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "--mixed-precision ${MIXED_PRECISION} \\\n",
        "--username ${HF_USERNAME} \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$DISABLE_GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--disable_gradient-checkpointing\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN}\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 18:37:49\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m388\u001b[0m - \u001b[1mRunning DreamBooth Training\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-16 18:37:49\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: log, data_path, func, inference, version, backend, train, deploy, train_split, valid_split, config\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 18:37:49\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 18:37:49\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mparmesan/000011 - Copie.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 18:37:49\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 18:37:49\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mparmesan/000011.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 18:37:49\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 18:37:49\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mparmesan/000018.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 18:37:49\u001b[0m | \u001b[36mautotrain.backends.local\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 18:37:49\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m360\u001b[0m - \u001b[1m['python', '-m', 'autotrain.trainers.dreambooth', '--training_config', 'parmesangrated/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 18:37:49\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m361\u001b[0m - \u001b[1m{'model': 'stabilityai/stable-diffusion-xl-base-1.0', 'vae_model': None, 'revision': None, 'tokenizer': None, 'image_path': 'parmesangrated/autotrain-data', 'class_image_path': None, 'prompt': 'An image of a grated parmesan cheese', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'parmesangrated', 'seed': 42, 'resolution': 1024, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 1, 'num_steps': 500, 'checkpointing_steps': 100000, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'disable_gradient_checkpointing': False, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': False, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': True, 'mixed_precision': 'fp16', 'token': '*****', 'push_to_hub': True, 'username': 'haroldng', 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-16 18:37:52\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[33m\u001b[1mFailed to download dataset: 404 Client Error. (Request ID: Root=1-66463660-0cdf833e1b506849498df0b5;2daeff81-7f27-4e00-ab48-21740333c4b6)\n",
            "\n",
            "Repository Not Found for url: https://huggingface.co/api/datasets/parmesangrated/autotrain-data/revision/main.\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are authenticated.\u001b[0m\n",
            "tokenizer/tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 737/737 [00:00<00:00, 1.93MB/s]\n",
            "tokenizer/vocab.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.06M/1.06M [00:00<00:00, 3.25MB/s]\n",
            "tokenizer/merges.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 525k/525k [00:00<00:00, 6.40MB/s]\n",
            "tokenizer/special_tokens_map.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 472/472 [00:00<00:00, 1.44MB/s]\n",
            "tokenizer_2/tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 725/725 [00:00<00:00, 2.00MB/s]\n",
            "tokenizer_2/special_tokens_map.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 460/460 [00:00<00:00, 1.39MB/s]\n",
            "text_encoder/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 565/565 [00:00<00:00, 1.69MB/s]\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "text_encoder_2/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 575/575 [00:00<00:00, 1.72MB/s]\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "model_index.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 609/609 [00:00<00:00, 1.69MB/s]\n",
            "scheduler/scheduler_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 479/479 [00:00<00:00, 4.61MB/s]\n",
            "{'rescale_betas_zero_snr', 'clip_sample_range', 'thresholding', 'dynamic_thresholding_ratio', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "text_encoder/model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 492M/492M [00:04<00:00, 116MB/s]\n",
            "text_encoder_2/model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.78G/2.78G [00:25<00:00, 110MB/s]\n",
            "vae/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 642/642 [00:00<00:00, 1.81MB/s]\n",
            "vae/diffusion_pytorch_model.safetensors: 100%|â–ˆ| 335M/335M [00:02<00:00, 117MB/s\n",
            "{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
            "unet/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.68k/1.68k [00:00<00:00, 4.65MB/s]\n",
            "unet/diffusion_pytorch_model.safetensors: 100%|â–ˆ| 10.3G/10.3G [01:29<00:00, 114M\n",
            "{'reverse_transformer_layers_per_block', 'dropout', 'attention_type'} was not found in config. Values will be initialized to default values.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 18:40:03\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m931\u001b[0m - \u001b[1m***** Running training *****\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 18:40:03\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1m  Num examples = 3\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 18:40:03\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m933\u001b[0m - \u001b[1m  Num batches each epoch = 3\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 18:40:03\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1m  Num Epochs = 500\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 18:40:03\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m935\u001b[0m - \u001b[1m  Instantaneous batch size per device = 1\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 18:40:03\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m936\u001b[0m - \u001b[1m  Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 18:40:03\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m937\u001b[0m - \u001b[1m  Gradient Accumulation steps = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 18:40:03\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m938\u001b[0m - \u001b[1m  Total optimization steps = 500\u001b[0m\n",
            "Steps:   0%|                                            | 0/500 [00:00<?, ?it/s]/Data/harold.ngoupeyou/cheese_challenge/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [24:27<00:00,  2.91s/it, loss=0.0958, lr=0.0001]Model weights saved in parmesangrated/pytorch_lora_weights.safetensors\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [24:27<00:00,  2.94s/it, loss=0.0958, lr=0.0001]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 19:04:31\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1mConverting model to Kohya format...\u001b[0m\n",
            "Upload 2 LFS files:   0%|                                 | 0/2 [00:00<?, ?it/s]\n",
            "pytorch_lora_weights_kohya.safetensors:   0%|       | 0.00/23.5M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   0%|             | 0.00/23.4M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:   3%| | 655k/23.5M [00:00<00:03, 6.40MB/\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   3%|â–    | 590k/23.4M [00:00<00:03, 5.80MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  17%|â–‹   | 4.00M/23.4M [00:00<00:01, 14.9MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  19%|â–| 4.37M/23.5M [00:00<00:01, 13.2MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  25%|â–ˆ   | 5.85M/23.4M [00:00<00:01, 13.4MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  32%|â–Ž| 7.45M/23.5M [00:00<00:00, 17.0MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  35%|â–ˆâ–  | 8.29M/23.4M [00:00<00:00, 15.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  62%|â–ˆâ–ˆâ– | 14.4M/23.4M [00:00<00:00, 27.6MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  46%|â–| 10.8M/23.5M [00:00<00:00, 15.4MB\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  59%|â–Œ| 13.9M/23.5M [00:00<00:00, 16.3MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  74%|â–ˆâ–ˆâ–‰ | 17.4M/23.4M [00:01<00:00, 17.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  84%|â–ˆâ–ˆâ–ˆâ–| 19.8M/23.4M [00:01<00:00, 17.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  96%|â–ˆâ–ˆâ–ˆâ–Š| 22.4M/23.4M [00:01<00:00, 17.2MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  68%|â–‹| 16.0M/23.5M [00:01<00:00, 10.3MB\u001b[A\n",
            "pytorch_lora_weights.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 23.4M/23.4M [00:02<00:00, 11.0MB/s]\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors: 100%|â–ˆ| 23.5M/23.5M [00:02<00:00, 9.51MB\n",
            "Upload 2 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.44s/it]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 19:04:37\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m393\u001b[0m - \u001b[1mJob ID: 360522\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "project_name = 'parmesangrated' # @param {type:\"string\"}\n",
        "model_name = 'stabilityai/stable-diffusion-xl-base-1.0' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\n",
        "prompt = 'An image of a grated parmesan cheese' # @param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "hf_username = \"haroldng\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "num_steps = 500 #@param {type:\"number\"}\n",
        "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "gradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "resolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\n",
        "use_8bit_adam = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_xformers = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "mixed_precision = \"fp16\" # @param [\"fp16\", \"bf16\", \"none\"] {type:\"raw\"}\n",
        "train_text_encoder = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "disable_gradient_checkpointing = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"MIXED_PRECISION\"] = str(mixed_precision)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"DISABLE_GRADIENT_CHECKPOINTING\"] = str(disable_gradient_checkpointing)\n",
        "os.environ[\"HF_USERNAME\"] = hf_username\n",
        "\n",
        "\n",
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--image-path parmesan/ \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "--mixed-precision ${MIXED_PRECISION} \\\n",
        "--username ${HF_USERNAME} \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$DISABLE_GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--disable_gradient-checkpointing\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN}\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 15:36:58\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m388\u001b[0m - \u001b[1mRunning DreamBooth Training\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-16 15:36:58\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[33m\u001b[1mParameters not supplied by user and set to default: vae_model\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-16 15:36:58\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: deploy, inference, backend, config, train_split, data_path, valid_split, train, func, version, log\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 15:36:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 15:36:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mpecorino/000000 - Copie (2).jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 15:36:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 15:36:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mpecorino/000000 - Copie.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 15:36:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 15:36:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mpecorino/000000.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 15:36:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 15:36:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mpecorino/000005.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 15:36:58\u001b[0m | \u001b[36mautotrain.backends.local\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 15:36:58\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m360\u001b[0m - \u001b[1m['python', '-m', 'autotrain.trainers.dreambooth', '--training_config', 'pecorinograted/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 15:36:58\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m361\u001b[0m - \u001b[1m{'model': 'stabilityai/stable-diffusion-xl-base-1.0', 'vae_model': None, 'revision': None, 'tokenizer': None, 'image_path': 'pecorinograted/autotrain-data', 'class_image_path': None, 'prompt': 'An image of a grated pecorino cheese', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'pecorinograted', 'seed': 42, 'resolution': 1024, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 1, 'num_steps': 500, 'checkpointing_steps': 100000, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'disable_gradient_checkpointing': False, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': False, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': True, 'mixed_precision': 'fp16', 'token': '*****', 'push_to_hub': True, 'username': 'haroldng', 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-16 15:37:00\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[33m\u001b[1mFailed to download dataset: 404 Client Error. (Request ID: Root=1-66460bfc-58c369466c8473af289ebc3e;cd61455a-d080-445d-9876-63657cda89a5)\n",
            "\n",
            "Repository Not Found for url: https://huggingface.co/api/datasets/pecorinograted/autotrain-data/revision/main.\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are authenticated.\u001b[0m\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "{'thresholding', 'clip_sample_range', 'rescale_betas_zero_snr', 'variance_type', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
            "{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "{'reverse_transformer_layers_per_block', 'dropout', 'attention_type'} was not found in config. Values will be initialized to default values.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 15:37:06\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m931\u001b[0m - \u001b[1m***** Running training *****\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 15:37:06\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1m  Num examples = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 15:37:06\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m933\u001b[0m - \u001b[1m  Num batches each epoch = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 15:37:06\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1m  Num Epochs = 500\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 15:37:06\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m935\u001b[0m - \u001b[1m  Instantaneous batch size per device = 1\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 15:37:06\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m936\u001b[0m - \u001b[1m  Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 15:37:06\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m937\u001b[0m - \u001b[1m  Gradient Accumulation steps = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 15:37:06\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m938\u001b[0m - \u001b[1m  Total optimization steps = 500\u001b[0m\n",
            "Steps:   0%|                                            | 0/500 [00:00<?, ?it/s]/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [34:30<00:00,  4.10s/it, loss=0.00572, lr=0.0001]\u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[32m2024-05-16 16:11:37\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mwrapper\u001b[0m:\u001b[36m120\u001b[0m - \u001b[31m\u001b[1mtrain has failed due to an exception: Traceback (most recent call last):\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/autotrain/trainers/common.py\", line 117, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/autotrain/trainers/dreambooth/__main__.py\", line 122, in train\n",
            "    main(_args)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/autotrain/trainers/dreambooth/train_xl.py\", line 1282, in main\n",
            "    unet = unet.to(torch.float32)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  [Previous line repeated 7 more times]\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 804, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "    return t.to(\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 50.00 MiB. GPU \n",
            "\u001b[0m\n",
            "\u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[32m2024-05-16 16:11:37\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mwrapper\u001b[0m:\u001b[36m121\u001b[0m - \u001b[31m\u001b[1mCUDA out of memory. Tried to allocate 50.00 MiB. GPU \u001b[0m\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [34:30<00:00,  4.14s/it, loss=0.00572, lr=0.0001]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:37\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m393\u001b[0m - \u001b[1mJob ID: 343710\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "project_name = 'pecorinograted' # @param {type:\"string\"}\n",
        "model_name = 'stabilityai/stable-diffusion-xl-base-1.0' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\n",
        "prompt = 'An image of a grated pecorino cheese' # @param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "hf_username = \"haroldng\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "num_steps = 500 #@param {type:\"number\"}\n",
        "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "gradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "resolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\n",
        "use_8bit_adam = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_xformers = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "mixed_precision = \"fp16\" # @param [\"fp16\", \"bf16\", \"none\"] {type:\"raw\"}\n",
        "train_text_encoder = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "disable_gradient_checkpointing = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"MIXED_PRECISION\"] = str(mixed_precision)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"DISABLE_GRADIENT_CHECKPOINTING\"] = str(disable_gradient_checkpointing)\n",
        "os.environ[\"HF_USERNAME\"] = hf_username\n",
        "\n",
        "\n",
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--image-path pecorino/ \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "--mixed-precision ${MIXED_PRECISION} \\\n",
        "--username ${HF_USERNAME} \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$DISABLE_GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--disable_gradient-checkpointing\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN}\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:41\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m388\u001b[0m - \u001b[1mRunning DreamBooth Training\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-16 16:11:41\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[33m\u001b[1mParameters not supplied by user and set to default: vae_model\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-16 16:11:41\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: train, deploy, train_split, backend, func, log, valid_split, data_path, version, config, inference\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:41\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:41\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mmothaisnew/000000.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:41\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:41\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mmothaisnew/000008.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:41\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:41\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mmothaisnew/000009.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:41\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:41\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mmothaisnew/000010.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:41\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:41\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mmothaisnew/000012.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:41\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:41\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mmothaisnew/000013.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:41\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:41\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mmothaisnew/000020.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:41\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:41\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mmothaisnew/000023.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:41\u001b[0m | \u001b[36mautotrain.backends.local\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:41\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m360\u001b[0m - \u001b[1m['python', '-m', 'autotrain.trainers.dreambooth', '--training_config', 'mothaisnew/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:41\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m361\u001b[0m - \u001b[1m{'model': 'stabilityai/stable-diffusion-xl-base-1.0', 'vae_model': None, 'revision': None, 'tokenizer': None, 'image_path': 'mothaisnew/autotrain-data', 'class_image_path': None, 'prompt': 'An image of the Mothais cheese', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'mothaisnew', 'seed': 42, 'resolution': 1024, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 1, 'num_steps': 500, 'checkpointing_steps': 100000, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'disable_gradient_checkpointing': False, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': False, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': True, 'mixed_precision': 'fp16', 'token': '*****', 'push_to_hub': True, 'username': 'haroldng', 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-16 16:11:43\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[33m\u001b[1mFailed to download dataset: 404 Client Error. (Request ID: Root=1-6646141f-0dbbdd4502a1ea323955c13c;501cb22a-42fd-419d-9f17-e33df3066bb8)\n",
            "\n",
            "Repository Not Found for url: https://huggingface.co/api/datasets/mothaisnew/autotrain-data/revision/main.\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are authenticated.\u001b[0m\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "{'thresholding', 'clip_sample_range', 'variance_type', 'rescale_betas_zero_snr', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
            "{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
            "{'dropout', 'attention_type', 'reverse_transformer_layers_per_block'} was not found in config. Values will be initialized to default values.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:49\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m931\u001b[0m - \u001b[1m***** Running training *****\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:49\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1m  Num examples = 8\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:49\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m933\u001b[0m - \u001b[1m  Num batches each epoch = 8\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:49\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1m  Num Epochs = 250\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:49\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m935\u001b[0m - \u001b[1m  Instantaneous batch size per device = 1\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:49\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m936\u001b[0m - \u001b[1m  Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:49\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m937\u001b[0m - \u001b[1m  Gradient Accumulation steps = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:11:49\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m938\u001b[0m - \u001b[1m  Total optimization steps = 500\u001b[0m\n",
            "Steps:   0%|                                            | 0/500 [00:00<?, ?it/s]/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [34:04<00:00,  4.09s/it, loss=0.00523, lr=0.0001]\u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[32m2024-05-16 16:45:53\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mwrapper\u001b[0m:\u001b[36m120\u001b[0m - \u001b[31m\u001b[1mtrain has failed due to an exception: Traceback (most recent call last):\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/autotrain/trainers/common.py\", line 117, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/autotrain/trainers/dreambooth/__main__.py\", line 122, in train\n",
            "    main(_args)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/autotrain/trainers/dreambooth/train_xl.py\", line 1282, in main\n",
            "    unet = unet.to(torch.float32)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  [Previous line repeated 7 more times]\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 804, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "    return t.to(\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 50.00 MiB. GPU \n",
            "\u001b[0m\n",
            "\u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[32m2024-05-16 16:45:53\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mwrapper\u001b[0m:\u001b[36m121\u001b[0m - \u001b[31m\u001b[1mCUDA out of memory. Tried to allocate 50.00 MiB. GPU \u001b[0m\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [34:04<00:00,  4.09s/it, loss=0.00523, lr=0.0001]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:45:54\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m393\u001b[0m - \u001b[1mJob ID: 350429\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "project_name = 'mothaisnew' # @param {type:\"string\"}\n",
        "model_name = 'stabilityai/stable-diffusion-xl-base-1.0' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\n",
        "prompt = 'An image of the Mothais cheese' # @param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "hf_username = \"haroldng\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "num_steps = 500 #@param {type:\"number\"}\n",
        "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "gradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "resolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\n",
        "use_8bit_adam = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_xformers = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "mixed_precision = \"fp16\" # @param [\"fp16\", \"bf16\", \"none\"] {type:\"raw\"}\n",
        "train_text_encoder = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "disable_gradient_checkpointing = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"MIXED_PRECISION\"] = str(mixed_precision)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"DISABLE_GRADIENT_CHECKPOINTING\"] = str(disable_gradient_checkpointing)\n",
        "os.environ[\"HF_USERNAME\"] = hf_username\n",
        "\n",
        "\n",
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--image-path mothaisnew/ \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "--mixed-precision ${MIXED_PRECISION} \\\n",
        "--username ${HF_USERNAME} \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$DISABLE_GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--disable_gradient-checkpointing\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN}\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:45:58\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m388\u001b[0m - \u001b[1mRunning DreamBooth Training\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-16 16:45:58\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[33m\u001b[1mParameters not supplied by user and set to default: vae_model\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-16 16:45:58\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: version, config, train_split, backend, data_path, valid_split, func, inference, deploy, train, log\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:45:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:45:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mcomte/000003 - Copie.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:45:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:45:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mcomte/000003.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:45:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:45:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mcomte/000016.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:45:58\u001b[0m | \u001b[36mautotrain.backends.local\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:45:58\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m360\u001b[0m - \u001b[1m['python', '-m', 'autotrain.trainers.dreambooth', '--training_config', 'comtegrated/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:45:58\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m361\u001b[0m - \u001b[1m{'model': 'stabilityai/stable-diffusion-xl-base-1.0', 'vae_model': None, 'revision': None, 'tokenizer': None, 'image_path': 'comtegrated/autotrain-data', 'class_image_path': None, 'prompt': 'An image of a grated comte cheese', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'comtegrated', 'seed': 42, 'resolution': 1024, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 1, 'num_steps': 500, 'checkpointing_steps': 100000, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'disable_gradient_checkpointing': False, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': False, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': True, 'mixed_precision': 'fp16', 'token': '*****', 'push_to_hub': True, 'username': 'haroldng', 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-16 16:46:00\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[33m\u001b[1mFailed to download dataset: 404 Client Error. (Request ID: Root=1-66461c28-4cb3f3286ab6f492154ac29c;7de0a7e6-0188-4725-9137-09cd20abb580)\n",
            "\n",
            "Repository Not Found for url: https://huggingface.co/api/datasets/comtegrated/autotrain-data/revision/main.\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are authenticated.\u001b[0m\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "{'rescale_betas_zero_snr', 'thresholding', 'clip_sample_range', 'dynamic_thresholding_ratio', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "{'dropout', 'attention_type', 'reverse_transformer_layers_per_block'} was not found in config. Values will be initialized to default values.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:46:07\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m931\u001b[0m - \u001b[1m***** Running training *****\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:46:07\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1m  Num examples = 3\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:46:07\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m933\u001b[0m - \u001b[1m  Num batches each epoch = 3\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:46:07\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1m  Num Epochs = 500\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:46:07\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m935\u001b[0m - \u001b[1m  Instantaneous batch size per device = 1\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:46:07\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m936\u001b[0m - \u001b[1m  Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:46:07\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m937\u001b[0m - \u001b[1m  Gradient Accumulation steps = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 16:46:07\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m938\u001b[0m - \u001b[1m  Total optimization steps = 500\u001b[0m\n",
            "Steps:   0%|                                            | 0/500 [00:00<?, ?it/s]/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [25:47<00:00,  3.11s/it, loss=0.0773, lr=0.0001]\u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[32m2024-05-16 17:11:54\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mwrapper\u001b[0m:\u001b[36m120\u001b[0m - \u001b[31m\u001b[1mtrain has failed due to an exception: Traceback (most recent call last):\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/autotrain/trainers/common.py\", line 117, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/autotrain/trainers/dreambooth/__main__.py\", line 122, in train\n",
            "    main(_args)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/autotrain/trainers/dreambooth/train_xl.py\", line 1282, in main\n",
            "    unet = unet.to(torch.float32)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  [Previous line repeated 7 more times]\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 804, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/Data/harold.ngoupeyou/cheese_challenge/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "    return t.to(\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 50.00 MiB. GPU \n",
            "\u001b[0m\n",
            "\u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[32m2024-05-16 17:11:54\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mwrapper\u001b[0m:\u001b[36m121\u001b[0m - \u001b[31m\u001b[1mCUDA out of memory. Tried to allocate 50.00 MiB. GPU \u001b[0m\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [25:47<00:00,  3.09s/it, loss=0.0773, lr=0.0001]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-16 17:11:55\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m393\u001b[0m - \u001b[1mJob ID: 357401\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "project_name = 'comtegrated' # @param {type:\"string\"}\n",
        "model_name = 'stabilityai/stable-diffusion-xl-base-1.0' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\n",
        "prompt = 'An image of a grated comte cheese' # @param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "hf_username = \"haroldng\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "num_steps = 500 #@param {type:\"number\"}\n",
        "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "gradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "resolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\n",
        "use_8bit_adam = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_xformers = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "mixed_precision = \"fp16\" # @param [\"fp16\", \"bf16\", \"none\"] {type:\"raw\"}\n",
        "train_text_encoder = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "disable_gradient_checkpointing = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"MIXED_PRECISION\"] = str(mixed_precision)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"DISABLE_GRADIENT_CHECKPOINTING\"] = str(disable_gradient_checkpointing)\n",
        "os.environ[\"HF_USERNAME\"] = hf_username\n",
        "\n",
        "\n",
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--image-path comte/ \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "--mixed-precision ${MIXED_PRECISION} \\\n",
        "--username ${HF_USERNAME} \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$DISABLE_GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--disable_gradient-checkpointing\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN}\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:26\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m388\u001b[0m - \u001b[1mRunning DreamBooth Training\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 00:39:26\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[33m\u001b[1mParameters not supplied by user and set to default: vae_model\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 00:39:26\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: inference, backend, func, version, log, deploy, train, config, data_path, train_split, valid_split\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:26\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:26\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesneufchatel/000000.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:26\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:26\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesneufchatel/000001.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:26\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:26\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesneufchatel/000002.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:26\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:26\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesneufchatel/000003.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:26\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:26\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesneufchatel/000007.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:26\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:26\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesneufchatel/000009.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:26\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:26\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesneufchatel/000012.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:26\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:26\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesneufchatel/000015.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:26\u001b[0m | \u001b[36mautotrain.backend\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:26\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m327\u001b[0m - \u001b[1m['python', '-m', 'autotrain.trainers.dreambooth', '--training_config', 'neufchatel/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:26\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m328\u001b[0m - \u001b[1m{'model': 'stabilityai/stable-diffusion-xl-base-1.0', 'vae_model': None, 'revision': None, 'tokenizer': None, 'image_path': 'neufchatel/autotrain-data', 'class_image_path': None, 'prompt': 'An image of the Neuf Chatel cheese', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'neufchatel', 'seed': 42, 'resolution': 1024, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 1, 'num_steps': 500, 'checkpointing_steps': 100000, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'disable_gradient_checkpointing': False, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': False, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': True, 'mixed_precision': 'fp16', 'token': '*****', 'push_to_hub': True, 'username': 'haroldng', 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 00:39:30\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[33m\u001b[1mFailed to download dataset: 404 Client Error. (Request ID: Root=1-663aada2-63799c676497349f249964ff;427d8cdb-bdcc-4ad2-80cf-85363dd43e99)\n",
            "\n",
            "Repository Not Found for url: https://huggingface.co/api/datasets/neufchatel/autotrain-data/revision/main.\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are authenticated.\u001b[0m\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "{'dynamic_thresholding_ratio', 'thresholding', 'variance_type', 'rescale_betas_zero_snr', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
            "{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
            "{'reverse_transformer_layers_per_block', 'attention_type', 'dropout'} was not found in config. Values will be initialized to default values.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:37\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m931\u001b[0m - \u001b[1m***** Running training *****\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:37\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1m  Num examples = 8\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:37\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m933\u001b[0m - \u001b[1m  Num batches each epoch = 8\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:37\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1m  Num Epochs = 250\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:37\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m935\u001b[0m - \u001b[1m  Instantaneous batch size per device = 1\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:37\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m936\u001b[0m - \u001b[1m  Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:37\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m937\u001b[0m - \u001b[1m  Gradient Accumulation steps = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 00:39:37\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m938\u001b[0m - \u001b[1m  Total optimization steps = 500\u001b[0m\n",
            "Steps:   0%|                                            | 0/500 [00:00<?, ?it/s]/users/eleves-a/2022/noam-joud-harold.ngoupeyou/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [33:40<00:00,  4.00s/it, loss=0.00244, lr=0.0001]Model weights saved in neufchatel/pytorch_lora_weights.safetensors\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [33:40<00:00,  4.04s/it, loss=0.00244, lr=0.0001]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:17\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1mConverting model to Kohya format...\u001b[0m\n",
            "Upload 2 LFS files:   0%|                                 | 0/2 [00:00<?, ?it/s]\n",
            "pytorch_lora_weights_kohya.safetensors:   0%|       | 0.00/23.5M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   0%|             | 0.00/23.4M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:   0%| | 8.19k/23.5M [00:00<05:07, 76.3kB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   0%|    | 8.19k/23.4M [00:00<05:52, 66.3kB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   7%|â–Ž   | 1.56M/23.4M [00:00<00:02, 8.37MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  10%| | 2.36M/23.5M [00:00<00:02, 10.0MB\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  14%|â–| 3.32M/23.5M [00:00<00:02, 8.07MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  11%|â–   | 2.48M/23.4M [00:00<00:03, 5.70MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  22%|â–| 5.18M/23.5M [00:00<00:01, 10.3MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  24%|â–‰   | 5.54M/23.4M [00:00<00:01, 11.8MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  49%|â–| 11.5M/23.5M [00:00<00:00, 25.1MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  44%|â–ˆâ–‹  | 10.2M/23.4M [00:00<00:00, 21.0MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  68%|â–‹| 16.0M/23.5M [00:01<00:00, 16.2MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  68%|â–ˆâ–ˆâ–‹ | 16.0M/23.4M [00:01<00:00, 17.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  86%|â–ˆâ–ˆâ–ˆâ–| 20.2M/23.4M [00:01<00:00, 20.2MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  88%|â–‰| 20.5M/23.5M [00:01<00:00, 18.8MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  97%|â–ˆâ–ˆâ–ˆâ–Š| 22.6M/23.4M [00:01<00:00, 18.2MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 23.4M/23.4M [00:01<00:00, 11.9MB/s]\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors: 100%|â–ˆ| 23.5M/23.5M [00:02<00:00, 11.6MB\n",
            "Upload 2 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.14s/it]\n"
          ]
        }
      ],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "project_name = 'neufchatel' # @param {type:\"string\"}\n",
        "model_name = 'stabilityai/stable-diffusion-xl-base-1.0' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\n",
        "prompt = 'An image of the Neuf Chatel cheese' # @param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "hf_username = \"haroldng\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "num_steps = 500 #@param {type:\"number\"}\n",
        "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "gradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "resolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\n",
        "use_8bit_adam = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_xformers = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "mixed_precision = \"fp16\" # @param [\"fp16\", \"bf16\", \"none\"] {type:\"raw\"}\n",
        "train_text_encoder = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "disable_gradient_checkpointing = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"MIXED_PRECISION\"] = str(mixed_precision)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"DISABLE_GRADIENT_CHECKPOINTING\"] = str(disable_gradient_checkpointing)\n",
        "os.environ[\"HF_USERNAME\"] = hf_username\n",
        "\n",
        "\n",
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--image-path imagesneufchatel/ \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "--mixed-precision ${MIXED_PRECISION} \\\n",
        "--username ${HF_USERNAME} \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$DISABLE_GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--disable_gradient-checkpointing\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN}\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:28\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m388\u001b[0m - \u001b[1mRunning DreamBooth Training\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 01:13:28\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[33m\u001b[1mParameters not supplied by user and set to default: vae_model\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 01:13:28\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: version, train_split, inference, config, data_path, log, func, deploy, train, valid_split, backend\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesossauiraty/000003.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesossauiraty/000007.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesossauiraty/000013.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesossauiraty/000017.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesossauiraty/000018.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesossauiraty/000019.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesossauiraty/000021.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:28\u001b[0m | \u001b[36mautotrain.backend\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:28\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m327\u001b[0m - \u001b[1m['python', '-m', 'autotrain.trainers.dreambooth', '--training_config', 'ossauiraty/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:28\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m328\u001b[0m - \u001b[1m{'model': 'stabilityai/stable-diffusion-xl-base-1.0', 'vae_model': None, 'revision': None, 'tokenizer': None, 'image_path': 'ossauiraty/autotrain-data', 'class_image_path': None, 'prompt': 'An image of the Ossau Iraty cheese', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'ossauiraty', 'seed': 42, 'resolution': 1024, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 1, 'num_steps': 500, 'checkpointing_steps': 100000, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'disable_gradient_checkpointing': False, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': False, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': True, 'mixed_precision': 'fp16', 'token': '*****', 'push_to_hub': True, 'username': 'haroldng', 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 01:13:31\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[33m\u001b[1mFailed to download dataset: 404 Client Error. (Request ID: Root=1-663ab59b-54755074334abffc6a79aed2;f2e42ff8-0653-42c4-ab21-733433b4ce0e)\n",
            "\n",
            "Repository Not Found for url: https://huggingface.co/api/datasets/ossauiraty/autotrain-data/revision/main.\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are authenticated.\u001b[0m\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "{'variance_type', 'thresholding', 'dynamic_thresholding_ratio', 'rescale_betas_zero_snr', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
            "{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "{'dropout', 'reverse_transformer_layers_per_block', 'attention_type'} was not found in config. Values will be initialized to default values.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:38\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m931\u001b[0m - \u001b[1m***** Running training *****\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:38\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1m  Num examples = 7\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:38\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m933\u001b[0m - \u001b[1m  Num batches each epoch = 7\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:38\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1m  Num Epochs = 250\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:38\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m935\u001b[0m - \u001b[1m  Instantaneous batch size per device = 1\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:38\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m936\u001b[0m - \u001b[1m  Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:38\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m937\u001b[0m - \u001b[1m  Gradient Accumulation steps = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:13:38\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m938\u001b[0m - \u001b[1m  Total optimization steps = 500\u001b[0m\n",
            "Steps:   0%|                                            | 0/500 [00:00<?, ?it/s]/users/eleves-a/2022/noam-joud-harold.ngoupeyou/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [29:40<00:00,  3.43s/it, loss=0.000933, lr=0.0001]Model weights saved in ossauiraty/pytorch_lora_weights.safetensors\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [29:40<00:00,  3.56s/it, loss=0.000933, lr=0.0001]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:19\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1mConverting model to Kohya format...\u001b[0m\n",
            "Upload 2 LFS files:   0%|                                 | 0/2 [00:00<?, ?it/s]\n",
            "pytorch_lora_weights.safetensors:   0%|             | 0.00/23.4M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:   0%|       | 0.00/23.5M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:   0%| | 8.19k/23.5M [00:00<09:40, 40.4kB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:   0%|    | 8.19k/23.4M [00:00<09:51, 39.6kB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:  16%|â–| 3.70M/23.5M [00:00<00:01, 15.3MB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:  10%|â–   | 2.28M/23.4M [00:00<00:02, 7.55MB/s]\u001b[A\n",
            "pytorch_lora_weights.safetensors:  14%|â–Œ   | 3.24M/23.4M [00:00<00:02, 6.88MB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:  68%|â–‹| 16.0M/23.5M [00:00<00:00, 30.7MB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:  23%|â–‰   | 5.36M/23.4M [00:00<00:01, 9.97MB/s]\u001b[A\n",
            "pytorch_lora_weights.safetensors:  47%|â–ˆâ–Š  | 10.9M/23.4M [00:00<00:00, 22.0MB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:  90%|â–‰| 21.2M/23.5M [00:00<00:00, 32.5MB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 23.4M/23.4M [00:01<00:00, 16.2MB/s]\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors: 100%|â–ˆ| 23.5M/23.5M [00:01<00:00, 15.2MB\n",
            "Upload 2 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.10it/s]\n"
          ]
        }
      ],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "project_name = 'ossauiraty' # @param {type:\"string\"}\n",
        "model_name = 'stabilityai/stable-diffusion-xl-base-1.0' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\n",
        "prompt = 'An image of the Ossau Iraty cheese' # @param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "hf_username = \"haroldng\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "num_steps = 500 #@param {type:\"number\"}\n",
        "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "gradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "resolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\n",
        "use_8bit_adam = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_xformers = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "mixed_precision = \"fp16\" # @param [\"fp16\", \"bf16\", \"none\"] {type:\"raw\"}\n",
        "train_text_encoder = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "disable_gradient_checkpointing = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"MIXED_PRECISION\"] = str(mixed_precision)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"DISABLE_GRADIENT_CHECKPOINTING\"] = str(disable_gradient_checkpointing)\n",
        "os.environ[\"HF_USERNAME\"] = hf_username\n",
        "\n",
        "\n",
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--image-path imagesossauiraty/ \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "--mixed-precision ${MIXED_PRECISION} \\\n",
        "--username ${HF_USERNAME} \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$DISABLE_GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--disable_gradient-checkpointing\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN}\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:29\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m388\u001b[0m - \u001b[1mRunning DreamBooth Training\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 01:43:29\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[33m\u001b[1mParameters not supplied by user and set to default: vae_model\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 01:43:29\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: data_path, inference, train_split, config, func, version, deploy, log, train, valid_split, backend\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:29\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:29\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesparmesan/000008.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:29\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:29\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesparmesan/000010.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:29\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:29\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesparmesan/000012.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:29\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:29\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesparmesan/000014.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:29\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:29\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesparmesan/000016.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:29\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:29\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesparmesan/000017.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:29\u001b[0m | \u001b[36mautotrain.backend\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:29\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m327\u001b[0m - \u001b[1m['python', '-m', 'autotrain.trainers.dreambooth', '--training_config', 'parmesan/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:29\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m328\u001b[0m - \u001b[1m{'model': 'stabilityai/stable-diffusion-xl-base-1.0', 'vae_model': None, 'revision': None, 'tokenizer': None, 'image_path': 'parmesan/autotrain-data', 'class_image_path': None, 'prompt': 'An image of the Parmesan cheese', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'parmesan', 'seed': 42, 'resolution': 1024, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 1, 'num_steps': 500, 'checkpointing_steps': 100000, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'disable_gradient_checkpointing': False, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': False, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': True, 'mixed_precision': 'fp16', 'token': '*****', 'push_to_hub': True, 'username': 'haroldng', 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 01:43:32\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[33m\u001b[1mFailed to download dataset: 404 Client Error. (Request ID: Root=1-663abca4-5581ab615a36c6ca00e4dad6;33a33538-afcc-4cd9-b526-9a118abc1311)\n",
            "\n",
            "Repository Not Found for url: https://huggingface.co/api/datasets/parmesan/autotrain-data/revision/main.\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are authenticated.\u001b[0m\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "{'variance_type', 'clip_sample_range', 'thresholding', 'rescale_betas_zero_snr', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
            "{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
            "{'attention_type', 'reverse_transformer_layers_per_block', 'dropout'} was not found in config. Values will be initialized to default values.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:39\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m931\u001b[0m - \u001b[1m***** Running training *****\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:39\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1m  Num examples = 6\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:39\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m933\u001b[0m - \u001b[1m  Num batches each epoch = 6\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:39\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1m  Num Epochs = 250\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:39\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m935\u001b[0m - \u001b[1m  Instantaneous batch size per device = 1\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:39\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m936\u001b[0m - \u001b[1m  Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:39\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m937\u001b[0m - \u001b[1m  Gradient Accumulation steps = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 01:43:39\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m938\u001b[0m - \u001b[1m  Total optimization steps = 500\u001b[0m\n",
            "Steps:   0%|                                            | 0/500 [00:00<?, ?it/s]/users/eleves-a/2022/noam-joud-harold.ngoupeyou/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [26:03<00:00,  2.94s/it, loss=0.0349, lr=0.0001]Model weights saved in parmesan/pytorch_lora_weights.safetensors\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [26:03<00:00,  3.13s/it, loss=0.0349, lr=0.0001]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:09:43\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1mConverting model to Kohya format...\u001b[0m\n",
            "Upload 2 LFS files:   0%|                                 | 0/2 [00:00<?, ?it/s]\n",
            "pytorch_lora_weights_kohya.safetensors:   0%|       | 0.00/23.5M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   0%|             | 0.00/23.4M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:   0%| | 8.19k/23.5M [00:00<07:06, 55.0kB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   0%|    | 8.19k/23.4M [00:00<06:52, 56.7kB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:   6%| | 1.46M/23.5M [00:00<00:03, 7.11MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   7%|â–Ž   | 1.72M/23.4M [00:00<00:04, 5.21MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  10%| | 2.31M/23.5M [00:00<00:04, 4.67MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  10%|â–   | 2.29M/23.4M [00:00<00:04, 4.82MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  23%|â–| 5.46M/23.5M [00:00<00:01, 11.7MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  24%|â–‰   | 5.51M/23.4M [00:00<00:01, 12.5MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  42%|â–| 9.92M/23.5M [00:00<00:00, 20.4MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  53%|â–ˆâ–ˆ  | 12.3M/23.4M [00:00<00:00, 27.8MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  68%|â–‹| 16.0M/23.5M [00:01<00:00, 19.1MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  68%|â–ˆâ–ˆâ–‹ | 16.0M/23.4M [00:01<00:00, 18.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  83%|â–ˆâ–ˆâ–ˆâ–Ž| 19.4M/23.4M [00:01<00:00, 21.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors: 100%|â–ˆ| 23.5M/23.5M [00:01<00:00, 16.6MB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 23.4M/23.4M [00:02<00:00, 11.5MB/s]\n",
            "Upload 2 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.16s/it]\n"
          ]
        }
      ],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "project_name = 'parmesan' # @param {type:\"string\"}\n",
        "model_name = 'stabilityai/stable-diffusion-xl-base-1.0' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\n",
        "prompt = 'An image of the Parmesan cheese' # @param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "hf_username = \"haroldng\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "num_steps = 500 #@param {type:\"number\"}\n",
        "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "gradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "resolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\n",
        "use_8bit_adam = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_xformers = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "mixed_precision = \"fp16\" # @param [\"fp16\", \"bf16\", \"none\"] {type:\"raw\"}\n",
        "train_text_encoder = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "disable_gradient_checkpointing = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"MIXED_PRECISION\"] = str(mixed_precision)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"DISABLE_GRADIENT_CHECKPOINTING\"] = str(disable_gradient_checkpointing)\n",
        "os.environ[\"HF_USERNAME\"] = hf_username\n",
        "\n",
        "\n",
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--image-path imagesparmesan/ \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "--mixed-precision ${MIXED_PRECISION} \\\n",
        "--username ${HF_USERNAME} \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$DISABLE_GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--disable_gradient-checkpointing\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN}\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:09:53\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m388\u001b[0m - \u001b[1mRunning DreamBooth Training\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 02:09:53\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[33m\u001b[1mParameters not supplied by user and set to default: vae_model\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 02:09:53\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: version, log, train, inference, func, valid_split, config, deploy, backend, data_path, train_split\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:09:53\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:09:53\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagespoulignysaintpierre/000000.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:09:53\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:09:53\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagespoulignysaintpierre/000003.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:09:53\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:09:53\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagespoulignysaintpierre/000004.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:09:53\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:09:53\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagespoulignysaintpierre/000005.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:09:53\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:09:53\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagespoulignysaintpierre/000006.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:09:53\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:09:53\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagespoulignysaintpierre/000007.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:09:53\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:09:53\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagespoulignysaintpierre/000015.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:09:53\u001b[0m | \u001b[36mautotrain.backend\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:09:53\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m327\u001b[0m - \u001b[1m['python', '-m', 'autotrain.trainers.dreambooth', '--training_config', 'poulignysaintpierre/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:09:53\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m328\u001b[0m - \u001b[1m{'model': 'stabilityai/stable-diffusion-xl-base-1.0', 'vae_model': None, 'revision': None, 'tokenizer': None, 'image_path': 'poulignysaintpierre/autotrain-data', 'class_image_path': None, 'prompt': 'An image of the Pouligny Saint Pierre cheese', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'poulignysaintpierre', 'seed': 42, 'resolution': 1024, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 1, 'num_steps': 500, 'checkpointing_steps': 100000, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'disable_gradient_checkpointing': False, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': False, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': True, 'mixed_precision': 'fp16', 'token': '*****', 'push_to_hub': True, 'username': 'haroldng', 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 02:09:57\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[33m\u001b[1mFailed to download dataset: 404 Client Error. (Request ID: Root=1-663ac2d5-476677103013206945d08172;d4ae2728-900d-4ef8-ac49-bfe1ea82df0b)\n",
            "\n",
            "Repository Not Found for url: https://huggingface.co/api/datasets/poulignysaintpierre/autotrain-data/revision/main.\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are authenticated.\u001b[0m\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "{'thresholding', 'dynamic_thresholding_ratio', 'rescale_betas_zero_snr', 'variance_type', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
            "{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "{'reverse_transformer_layers_per_block', 'attention_type', 'dropout'} was not found in config. Values will be initialized to default values.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:10:04\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m931\u001b[0m - \u001b[1m***** Running training *****\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:10:04\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1m  Num examples = 7\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:10:04\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m933\u001b[0m - \u001b[1m  Num batches each epoch = 7\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:10:04\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1m  Num Epochs = 250\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:10:04\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m935\u001b[0m - \u001b[1m  Instantaneous batch size per device = 1\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:10:04\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m936\u001b[0m - \u001b[1m  Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:10:04\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m937\u001b[0m - \u001b[1m  Gradient Accumulation steps = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:10:04\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m938\u001b[0m - \u001b[1m  Total optimization steps = 500\u001b[0m\n",
            "Steps:   0%|                                            | 0/500 [00:00<?, ?it/s]/users/eleves-a/2022/noam-joud-harold.ngoupeyou/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [29:59<00:00,  3.47s/it, loss=0.000884, lr=0.0001]Model weights saved in poulignysaintpierre/pytorch_lora_weights.safetensors\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [30:00<00:00,  3.60s/it, loss=0.000884, lr=0.0001]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:04\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1mConverting model to Kohya format...\u001b[0m\n",
            "Upload 2 LFS files:   0%|                                 | 0/2 [00:00<?, ?it/s]\n",
            "pytorch_lora_weights_kohya.safetensors:   0%|       | 0.00/23.5M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   0%|             | 0.00/23.4M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:   0%| | 8.19k/23.5M [00:00<05:45, 67.9kB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   0%|    | 8.19k/23.4M [00:00<05:57, 65.4kB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:   6%| | 1.42M/23.5M [00:00<00:02, 7.59MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  10%|â–   | 2.27M/23.4M [00:00<00:02, 9.12MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  10%| | 2.24M/23.5M [00:00<00:04, 5.30MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  14%|â–Œ   | 3.23M/23.4M [00:00<00:02, 7.79MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  22%|â–| 5.13M/23.5M [00:00<00:01, 11.1MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  20%|â–Š   | 4.77M/23.4M [00:00<00:02, 9.10MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  43%|â–| 10.1M/23.5M [00:00<00:00, 21.6MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  46%|â–ˆâ–Š  | 10.7M/23.4M [00:00<00:00, 22.3MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  67%|â–‹| 15.7M/23.5M [00:00<00:00, 31.3MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  68%|â–ˆâ–ˆâ–‹ | 16.0M/23.4M [00:01<00:00, 16.9MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  82%|â–Š| 19.3M/23.5M [00:01<00:00, 16.5MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  85%|â–ˆâ–ˆâ–ˆâ–| 20.0M/23.4M [00:01<00:00, 19.5MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  94%|â–‰| 22.0M/23.5M [00:01<00:00, 16.2MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 23.4M/23.4M [00:01<00:00, 11.9MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors: 100%|â–ˆ| 23.5M/23.5M [00:01<00:00, 11.8MB\n",
            "Upload 2 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.15s/it]\n"
          ]
        }
      ],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "project_name = 'poulignysaintpierre' # @param {type:\"string\"}\n",
        "model_name = 'stabilityai/stable-diffusion-xl-base-1.0' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\n",
        "prompt = 'An image of the Pouligny Saint Pierre cheese' # @param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "hf_username = \"haroldng\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "num_steps = 500 #@param {type:\"number\"}\n",
        "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "gradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "resolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\n",
        "use_8bit_adam = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_xformers = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "mixed_precision = \"fp16\" # @param [\"fp16\", \"bf16\", \"none\"] {type:\"raw\"}\n",
        "train_text_encoder = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "disable_gradient_checkpointing = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"MIXED_PRECISION\"] = str(mixed_precision)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"DISABLE_GRADIENT_CHECKPOINTING\"] = str(disable_gradient_checkpointing)\n",
        "os.environ[\"HF_USERNAME\"] = hf_username\n",
        "\n",
        "\n",
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--image-path imagespoulignysaintpierre/ \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "--mixed-precision ${MIXED_PRECISION} \\\n",
        "--username ${HF_USERNAME} \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$DISABLE_GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--disable_gradient-checkpointing\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN}\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:14\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m388\u001b[0m - \u001b[1mRunning DreamBooth Training\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 02:40:14\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[33m\u001b[1mParameters not supplied by user and set to default: vae_model\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 02:40:14\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: log, valid_split, backend, func, data_path, train, config, version, train_split, inference, deploy\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:14\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:14\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesreblochon/000000.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:14\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:14\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesreblochon/000002.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:14\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:14\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesreblochon/000007.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:14\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:14\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesreblochon/000008.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:14\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:14\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesreblochon/000018.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:14\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:14\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesreblochon/000021.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:14\u001b[0m | \u001b[36mautotrain.backend\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:14\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m327\u001b[0m - \u001b[1m['python', '-m', 'autotrain.trainers.dreambooth', '--training_config', 'reblochon/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:14\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m328\u001b[0m - \u001b[1m{'model': 'stabilityai/stable-diffusion-xl-base-1.0', 'vae_model': None, 'revision': None, 'tokenizer': None, 'image_path': 'reblochon/autotrain-data', 'class_image_path': None, 'prompt': 'An image of the Reblochon cheese', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'reblochon', 'seed': 42, 'resolution': 1024, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 1, 'num_steps': 500, 'checkpointing_steps': 100000, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'disable_gradient_checkpointing': False, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': False, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': True, 'mixed_precision': 'fp16', 'token': '*****', 'push_to_hub': True, 'username': 'haroldng', 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 02:40:17\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[33m\u001b[1mFailed to download dataset: 404 Client Error. (Request ID: Root=1-663ac9f1-5e06a8ac4b7665325a8188ba;7598e90b-fcc3-421e-b7fe-3e214c7187d8)\n",
            "\n",
            "Repository Not Found for url: https://huggingface.co/api/datasets/reblochon/autotrain-data/revision/main.\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are authenticated.\u001b[0m\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "{'thresholding', 'dynamic_thresholding_ratio', 'clip_sample_range', 'rescale_betas_zero_snr', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "{'attention_type', 'reverse_transformer_layers_per_block', 'dropout'} was not found in config. Values will be initialized to default values.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:24\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m931\u001b[0m - \u001b[1m***** Running training *****\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:24\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1m  Num examples = 6\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:24\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m933\u001b[0m - \u001b[1m  Num batches each epoch = 6\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:24\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1m  Num Epochs = 250\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:24\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m935\u001b[0m - \u001b[1m  Instantaneous batch size per device = 1\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:24\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m936\u001b[0m - \u001b[1m  Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:24\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m937\u001b[0m - \u001b[1m  Gradient Accumulation steps = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 02:40:24\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m938\u001b[0m - \u001b[1m  Total optimization steps = 500\u001b[0m\n",
            "Steps:   0%|                                            | 0/500 [00:00<?, ?it/s]/users/eleves-a/2022/noam-joud-harold.ngoupeyou/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [26:00<00:00,  2.94s/it, loss=0.0881, lr=0.0001]Model weights saved in reblochon/pytorch_lora_weights.safetensors\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [26:00<00:00,  3.12s/it, loss=0.0881, lr=0.0001]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:25\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1mConverting model to Kohya format...\u001b[0m\n",
            "Upload 2 LFS files:   0%|                                 | 0/2 [00:00<?, ?it/s]\n",
            "pytorch_lora_weights.safetensors:   0%|             | 0.00/23.4M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:   0%|       | 0.00/23.5M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:   1%|     | 262k/23.4M [00:00<00:09, 2.50MB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:   2%| | 393k/23.5M [00:00<00:11, 2.09MB/\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:   2%|     | 516k/23.4M [00:00<00:13, 1.76MB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:   3%| | 647k/23.5M [00:00<00:12, 1.89MB/\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:  10%|â–   | 2.31M/23.4M [00:00<00:02, 7.56MB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:  15%|â–| 3.47M/23.5M [00:00<00:02, 8.49MB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:  15%|â–Œ   | 3.40M/23.4M [00:00<00:02, 7.65MB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:  18%|â–| 4.30M/23.5M [00:00<00:02, 7.26MB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:  18%|â–‹   | 4.25M/23.4M [00:00<00:02, 6.76MB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:  24%|â–| 5.64M/23.5M [00:00<00:02, 8.04MB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:  23%|â–‰   | 5.39M/23.4M [00:00<00:02, 7.24MB/s]\u001b[A\n",
            "pytorch_lora_weights.safetensors:  44%|â–ˆâ–Š  | 10.3M/23.4M [00:00<00:00, 17.8MB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:  45%|â–| 10.5M/23.5M [00:00<00:00, 17.3MB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:  68%|â–ˆâ–ˆâ–‹ | 16.0M/23.4M [00:01<00:00, 16.8MB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:  68%|â–‹| 16.0M/23.5M [00:01<00:00, 14.7MB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:  83%|â–ˆâ–ˆâ–ˆâ–Ž| 19.4M/23.4M [00:01<00:00, 18.9MB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:  86%|â–Š| 20.3M/23.5M [00:01<00:00, 18.1MB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:  92%|â–ˆâ–ˆâ–ˆâ–‹| 21.5M/23.4M [00:01<00:00, 18.4MB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors: 100%|â–ˆ| 23.5M/23.5M [00:02<00:00, 9.72MB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 23.4M/23.4M [00:02<00:00, 9.51MB/s]\n",
            "Upload 2 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.44s/it]\n"
          ]
        }
      ],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "project_name = 'reblochon' # @param {type:\"string\"}\n",
        "model_name = 'stabilityai/stable-diffusion-xl-base-1.0' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\n",
        "prompt = 'An image of the Reblochon cheese' # @param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "hf_username = \"haroldng\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "num_steps = 500 #@param {type:\"number\"}\n",
        "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "gradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "resolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\n",
        "use_8bit_adam = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_xformers = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "mixed_precision = \"fp16\" # @param [\"fp16\", \"bf16\", \"none\"] {type:\"raw\"}\n",
        "train_text_encoder = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "disable_gradient_checkpointing = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"MIXED_PRECISION\"] = str(mixed_precision)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"DISABLE_GRADIENT_CHECKPOINTING\"] = str(disable_gradient_checkpointing)\n",
        "os.environ[\"HF_USERNAME\"] = hf_username\n",
        "\n",
        "\n",
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--image-path imagesreblochon/ \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "--mixed-precision ${MIXED_PRECISION} \\\n",
        "--username ${HF_USERNAME} \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$DISABLE_GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--disable_gradient-checkpointing\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN}\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:35\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m388\u001b[0m - \u001b[1mRunning DreamBooth Training\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 03:06:35\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[33m\u001b[1mParameters not supplied by user and set to default: vae_model\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 03:06:35\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: config, func, deploy, data_path, train, valid_split, train_split, inference, backend, log, version\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:35\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:35\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesroquefort/000001.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:35\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:35\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesroquefort/000002.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:35\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:35\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesroquefort/000004.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:35\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:35\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesroquefort/000006.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:35\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:35\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesroquefort/000008.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:35\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:35\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesroquefort/000022.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:35\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:35\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesroquefort/000023.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:35\u001b[0m | \u001b[36mautotrain.backend\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:35\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m327\u001b[0m - \u001b[1m['python', '-m', 'autotrain.trainers.dreambooth', '--training_config', 'roquefort/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:35\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m328\u001b[0m - \u001b[1m{'model': 'stabilityai/stable-diffusion-xl-base-1.0', 'vae_model': None, 'revision': None, 'tokenizer': None, 'image_path': 'roquefort/autotrain-data', 'class_image_path': None, 'prompt': 'An image of the Roquefort cheese', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'roquefort', 'seed': 42, 'resolution': 1024, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 1, 'num_steps': 500, 'checkpointing_steps': 100000, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'disable_gradient_checkpointing': False, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': False, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': True, 'mixed_precision': 'fp16', 'token': '*****', 'push_to_hub': True, 'username': 'haroldng', 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 03:06:39\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[33m\u001b[1mFailed to download dataset: 404 Client Error. (Request ID: Root=1-663ad01f-7b1dc8a400476c0218ab040b;a1ecfe47-1fe3-4d03-8df8-8781aa0088ed)\n",
            "\n",
            "Repository Not Found for url: https://huggingface.co/api/datasets/roquefort/autotrain-data/revision/main.\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are authenticated.\u001b[0m\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "{'clip_sample_range', 'variance_type', 'dynamic_thresholding_ratio', 'thresholding', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
            "{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
            "{'attention_type', 'dropout', 'reverse_transformer_layers_per_block'} was not found in config. Values will be initialized to default values.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:46\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m931\u001b[0m - \u001b[1m***** Running training *****\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:46\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1m  Num examples = 7\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:46\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m933\u001b[0m - \u001b[1m  Num batches each epoch = 7\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:46\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1m  Num Epochs = 250\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:46\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m935\u001b[0m - \u001b[1m  Instantaneous batch size per device = 1\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:46\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m936\u001b[0m - \u001b[1m  Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:46\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m937\u001b[0m - \u001b[1m  Gradient Accumulation steps = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:06:46\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m938\u001b[0m - \u001b[1m  Total optimization steps = 500\u001b[0m\n",
            "Steps:   0%|                                            | 0/500 [00:00<?, ?it/s]/users/eleves-a/2022/noam-joud-harold.ngoupeyou/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [29:31<00:00,  3.43s/it, loss=0.0012, lr=0.0001]Model weights saved in roquefort/pytorch_lora_weights.safetensors\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [29:31<00:00,  3.54s/it, loss=0.0012, lr=0.0001]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:18\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1mConverting model to Kohya format...\u001b[0m\n",
            "Upload 2 LFS files:   0%|                                 | 0/2 [00:00<?, ?it/s]\n",
            "pytorch_lora_weights.safetensors:   0%|             | 0.00/23.4M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:   0%|       | 0.00/23.5M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:   0%| | 8.19k/23.5M [00:00<05:57, 65.7kB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:   0%|    | 8.19k/23.4M [00:00<07:01, 55.5kB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:   2%| | 393k/23.5M [00:00<00:11, 2.04MB/\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:   2%|     | 434k/23.4M [00:00<00:13, 1.71MB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:   3%| | 647k/23.5M [00:00<00:12, 1.86MB/\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:   3%|â–    | 696k/23.4M [00:00<00:11, 1.99MB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:  13%|â–| 3.15M/23.5M [00:00<00:02, 8.60MB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:  13%|â–Œ   | 3.13M/23.4M [00:00<00:02, 8.53MB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:  17%|â–| 4.04M/23.5M [00:00<00:02, 7.45MB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:  17%|â–‹   | 4.02M/23.4M [00:00<00:02, 7.04MB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:  22%|â–| 5.13M/23.5M [00:00<00:02, 7.59MB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:  21%|â–Š   | 4.99M/23.4M [00:00<00:02, 7.41MB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:  32%|â–Ž| 7.44M/23.5M [00:00<00:01, 10.9MB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:  32%|â–ˆâ–Ž  | 7.49M/23.4M [00:00<00:01, 11.2MB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:  64%|â–‹| 15.0M/23.5M [00:01<00:00, 27.4MB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:  67%|â–ˆâ–ˆâ–‹ | 15.6M/23.4M [00:01<00:00, 28.4MB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:  77%|â–Š| 18.1M/23.5M [00:01<00:00, 16.2MB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 23.4M/23.4M [00:01<00:00, 13.2MB/s]\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors: 100%|â–ˆ| 23.5M/23.5M [00:01<00:00, 12.9MB\n",
            "Upload 2 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.07s/it]\n"
          ]
        }
      ],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "project_name = 'roquefort' # @param {type:\"string\"}\n",
        "model_name = 'stabilityai/stable-diffusion-xl-base-1.0' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\n",
        "prompt = 'An image of the Roquefort cheese' # @param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "hf_username = \"haroldng\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "num_steps = 500 #@param {type:\"number\"}\n",
        "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "gradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "resolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\n",
        "use_8bit_adam = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_xformers = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "mixed_precision = \"fp16\" # @param [\"fp16\", \"bf16\", \"none\"] {type:\"raw\"}\n",
        "train_text_encoder = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "disable_gradient_checkpointing = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"MIXED_PRECISION\"] = str(mixed_precision)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"DISABLE_GRADIENT_CHECKPOINTING\"] = str(disable_gradient_checkpointing)\n",
        "os.environ[\"HF_USERNAME\"] = hf_username\n",
        "\n",
        "\n",
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--image-path imagesroquefort/ \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "--mixed-precision ${MIXED_PRECISION} \\\n",
        "--username ${HF_USERNAME} \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$DISABLE_GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--disable_gradient-checkpointing\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN}\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:28\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m388\u001b[0m - \u001b[1mRunning DreamBooth Training\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 03:36:28\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[33m\u001b[1mParameters not supplied by user and set to default: vae_model\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 03:36:28\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: inference, train, deploy, log, data_path, valid_split, config, func, train_split, version, backend\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagessaintfelicien/000000.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagessaintfelicien/000001.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagessaintfelicien/000004.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagessaintfelicien/000005.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagessaintfelicien/000010.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:28\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagessaintfelicien/000014.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:28\u001b[0m | \u001b[36mautotrain.backend\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:28\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m327\u001b[0m - \u001b[1m['python', '-m', 'autotrain.trainers.dreambooth', '--training_config', 'saintfelicien/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:28\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m328\u001b[0m - \u001b[1m{'model': 'stabilityai/stable-diffusion-xl-base-1.0', 'vae_model': None, 'revision': None, 'tokenizer': None, 'image_path': 'saintfelicien/autotrain-data', 'class_image_path': None, 'prompt': 'An image of the Saint Felicien cheese', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'saintfelicien', 'seed': 42, 'resolution': 1024, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 1, 'num_steps': 500, 'checkpointing_steps': 100000, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'disable_gradient_checkpointing': False, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': False, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': True, 'mixed_precision': 'fp16', 'token': '*****', 'push_to_hub': True, 'username': 'haroldng', 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 03:36:31\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[33m\u001b[1mFailed to download dataset: 404 Client Error. (Request ID: Root=1-663ad71f-5776d940556959fd10625925;cd0f6bcb-a3a1-405c-9c57-483edb7a1b31)\n",
            "\n",
            "Repository Not Found for url: https://huggingface.co/api/datasets/saintfelicien/autotrain-data/revision/main.\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are authenticated.\u001b[0m\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "{'rescale_betas_zero_snr', 'variance_type', 'dynamic_thresholding_ratio', 'thresholding', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
            "{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "{'reverse_transformer_layers_per_block', 'attention_type', 'dropout'} was not found in config. Values will be initialized to default values.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:38\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m931\u001b[0m - \u001b[1m***** Running training *****\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:38\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1m  Num examples = 6\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:38\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m933\u001b[0m - \u001b[1m  Num batches each epoch = 6\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:38\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1m  Num Epochs = 250\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:38\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m935\u001b[0m - \u001b[1m  Instantaneous batch size per device = 1\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:38\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m936\u001b[0m - \u001b[1m  Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:38\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m937\u001b[0m - \u001b[1m  Gradient Accumulation steps = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 03:36:38\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m938\u001b[0m - \u001b[1m  Total optimization steps = 500\u001b[0m\n",
            "Steps:   0%|                                            | 0/500 [00:00<?, ?it/s]/users/eleves-a/2022/noam-joud-harold.ngoupeyou/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [25:30<00:00,  2.88s/it, loss=0.0992, lr=0.0001]Model weights saved in saintfelicien/pytorch_lora_weights.safetensors\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [25:30<00:00,  3.06s/it, loss=0.0992, lr=0.0001]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:08\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1mConverting model to Kohya format...\u001b[0m\n",
            "Upload 2 LFS files:   0%|                                 | 0/2 [00:00<?, ?it/s]\n",
            "pytorch_lora_weights_kohya.safetensors:   0%|       | 0.00/23.5M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   0%|             | 0.00/23.4M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:   0%| | 8.19k/23.5M [00:00<05:50, 67.0kB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   0%|    | 8.19k/23.4M [00:00<07:48, 49.9kB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:   4%| | 885k/23.5M [00:00<00:04, 4.72MB/\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   5%|â–   | 1.22M/23.4M [00:00<00:03, 5.67MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:   6%| | 1.40M/23.5M [00:00<00:05, 4.01MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   8%|â–Ž   | 1.94M/23.4M [00:00<00:04, 5.09MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  18%|â–| 4.22M/23.5M [00:00<00:01, 10.3MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  16%|â–‹   | 3.77M/23.4M [00:00<00:02, 9.16MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  22%|â–‰   | 5.18M/23.4M [00:00<00:02, 8.74MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  23%|â–| 5.50M/23.5M [00:00<00:01, 9.03MB\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  32%|â–Ž| 7.56M/23.5M [00:00<00:01, 12.0MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  29%|â–ˆâ–  | 6.72M/23.4M [00:00<00:01, 9.35MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  41%|â–| 9.67M/23.5M [00:00<00:01, 13.2MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  39%|â–ˆâ–Œ  | 9.15M/23.4M [00:00<00:01, 12.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  68%|â–ˆâ–ˆâ–‹ | 16.0M/23.4M [00:01<00:00, 15.1MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  68%|â–‹| 16.0M/23.5M [00:01<00:00, 13.8MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  85%|â–ˆâ–ˆâ–ˆâ–| 19.9M/23.4M [00:01<00:00, 18.1MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  88%|â–‰| 20.8M/23.5M [00:01<00:00, 17.0MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 23.4M/23.4M [00:02<00:00, 10.3MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors: 100%|â–ˆ| 23.5M/23.5M [00:02<00:00, 9.24MB\n",
            "Upload 2 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.44s/it]\n"
          ]
        }
      ],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "project_name = 'saintfelicien' # @param {type:\"string\"}\n",
        "model_name = 'stabilityai/stable-diffusion-xl-base-1.0' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\n",
        "prompt = 'An image of the Saint Felicien cheese' # @param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "hf_username = \"haroldng\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "num_steps = 500 #@param {type:\"number\"}\n",
        "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "gradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "resolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\n",
        "use_8bit_adam = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_xformers = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "mixed_precision = \"fp16\" # @param [\"fp16\", \"bf16\", \"none\"] {type:\"raw\"}\n",
        "train_text_encoder = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "disable_gradient_checkpointing = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"MIXED_PRECISION\"] = str(mixed_precision)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"DISABLE_GRADIENT_CHECKPOINTING\"] = str(disable_gradient_checkpointing)\n",
        "os.environ[\"HF_USERNAME\"] = hf_username\n",
        "\n",
        "\n",
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--image-path imagessaintfelicien/ \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "--mixed-precision ${MIXED_PRECISION} \\\n",
        "--username ${HF_USERNAME} \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$DISABLE_GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--disable_gradient-checkpointing\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN}\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:20\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m388\u001b[0m - \u001b[1mRunning DreamBooth Training\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 04:02:20\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[33m\u001b[1mParameters not supplied by user and set to default: vae_model\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 04:02:20\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: train, valid_split, train_split, config, inference, log, data_path, version, deploy, func, backend\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:20\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:20\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagessaintnectaire/000001.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:20\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:20\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagessaintnectaire/000003.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:20\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:20\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagessaintnectaire/000005.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:20\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:20\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagessaintnectaire/000006.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:20\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:20\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagessaintnectaire/000008.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:20\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:20\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagessaintnectaire/000009.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:20\u001b[0m | \u001b[36mautotrain.backend\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:20\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m327\u001b[0m - \u001b[1m['python', '-m', 'autotrain.trainers.dreambooth', '--training_config', 'saintnectaire/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:20\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m328\u001b[0m - \u001b[1m{'model': 'stabilityai/stable-diffusion-xl-base-1.0', 'vae_model': None, 'revision': None, 'tokenizer': None, 'image_path': 'saintnectaire/autotrain-data', 'class_image_path': None, 'prompt': 'An image of the Saint Nectaire cheese', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'saintnectaire', 'seed': 42, 'resolution': 1024, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 1, 'num_steps': 500, 'checkpointing_steps': 100000, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'disable_gradient_checkpointing': False, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': False, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': True, 'mixed_precision': 'fp16', 'token': '*****', 'push_to_hub': True, 'username': 'haroldng', 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 04:02:23\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[33m\u001b[1mFailed to download dataset: 404 Client Error. (Request ID: Root=1-663add2f-20e629d16f408eab34804d3c;17751618-09e2-435e-9ac9-34166ae348b7)\n",
            "\n",
            "Repository Not Found for url: https://huggingface.co/api/datasets/saintnectaire/autotrain-data/revision/main.\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are authenticated.\u001b[0m\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "{'variance_type', 'thresholding', 'clip_sample_range', 'rescale_betas_zero_snr', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
            "{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "{'attention_type', 'reverse_transformer_layers_per_block', 'dropout'} was not found in config. Values will be initialized to default values.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:30\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m931\u001b[0m - \u001b[1m***** Running training *****\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:30\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1m  Num examples = 6\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:30\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m933\u001b[0m - \u001b[1m  Num batches each epoch = 6\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:30\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1m  Num Epochs = 250\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:30\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m935\u001b[0m - \u001b[1m  Instantaneous batch size per device = 1\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:30\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m936\u001b[0m - \u001b[1m  Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:30\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m937\u001b[0m - \u001b[1m  Gradient Accumulation steps = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:02:30\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m938\u001b[0m - \u001b[1m  Total optimization steps = 500\u001b[0m\n",
            "Steps:   0%|                                            | 0/500 [00:00<?, ?it/s]/users/eleves-a/2022/noam-joud-harold.ngoupeyou/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [25:16<00:00,  2.83s/it, loss=0.0524, lr=0.0001]Model weights saved in saintnectaire/pytorch_lora_weights.safetensors\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [25:16<00:00,  3.03s/it, loss=0.0524, lr=0.0001]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:27:47\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1mConverting model to Kohya format...\u001b[0m\n",
            "Upload 2 LFS files:   0%|                                 | 0/2 [00:00<?, ?it/s]\n",
            "pytorch_lora_weights_kohya.safetensors:   0%|       | 0.00/23.5M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   0%|             | 0.00/23.4M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   0%|    | 8.19k/23.4M [00:00<06:19, 61.5kB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:   0%| | 8.19k/23.5M [00:00<06:38, 58.8kB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   4%|â–    | 958k/23.4M [00:00<00:04, 4.81MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:   2%| | 393k/23.5M [00:00<00:12, 1.92MB/\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   6%|â–Ž   | 1.49M/23.4M [00:00<00:05, 4.15MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:   3%| | 647k/23.5M [00:00<00:12, 1.80MB/\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  18%|â–‹   | 4.23M/23.4M [00:00<00:01, 10.3MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  14%|â–| 3.40M/23.5M [00:00<00:02, 7.91MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  24%|â–‰   | 5.64M/23.4M [00:00<00:01, 9.42MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  18%|â–| 4.24M/23.5M [00:00<00:02, 7.18MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  31%|â–ˆâ–  | 7.30M/23.4M [00:00<00:01, 9.93MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  22%|â–| 5.26M/23.5M [00:00<00:02, 7.26MB\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  38%|â–| 8.85M/23.5M [00:00<00:01, 14.2MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  47%|â–ˆâ–‰  | 11.0M/23.4M [00:00<00:00, 16.1MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  65%|â–‹| 15.2M/23.5M [00:01<00:00, 26.4MB\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  77%|â–Š| 18.1M/23.5M [00:01<00:00, 21.3MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  68%|â–ˆâ–ˆâ–‹ | 16.0M/23.4M [00:01<00:00, 14.3MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  88%|â–‰| 20.6M/23.5M [00:01<00:00, 17.7MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  87%|â–ˆâ–ˆâ–ˆâ–| 20.4M/23.4M [00:01<00:00, 17.2MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  99%|â–‰| 23.1M/23.5M [00:01<00:00, 16.8MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 23.4M/23.4M [00:02<00:00, 10.5MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors: 100%|â–ˆ| 23.5M/23.5M [00:02<00:00, 9.25MB\n",
            "Upload 2 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.40s/it]\n"
          ]
        }
      ],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "project_name = 'saintnectaire' # @param {type:\"string\"}\n",
        "model_name = 'stabilityai/stable-diffusion-xl-base-1.0' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\n",
        "prompt = 'An image of the Saint Nectaire cheese' # @param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "hf_username = \"haroldng\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "num_steps = 500 #@param {type:\"number\"}\n",
        "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "gradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "resolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\n",
        "use_8bit_adam = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_xformers = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "mixed_precision = \"fp16\" # @param [\"fp16\", \"bf16\", \"none\"] {type:\"raw\"}\n",
        "train_text_encoder = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "disable_gradient_checkpointing = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"MIXED_PRECISION\"] = str(mixed_precision)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"DISABLE_GRADIENT_CHECKPOINTING\"] = str(disable_gradient_checkpointing)\n",
        "os.environ[\"HF_USERNAME\"] = hf_username\n",
        "\n",
        "\n",
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--image-path imagessaintnectaire/ \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "--mixed-precision ${MIXED_PRECISION} \\\n",
        "--username ${HF_USERNAME} \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$DISABLE_GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--disable_gradient-checkpointing\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN}\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:27:58\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m388\u001b[0m - \u001b[1mRunning DreamBooth Training\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 04:27:58\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[33m\u001b[1mParameters not supplied by user and set to default: vae_model\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 04:27:58\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: train_split, version, log, valid_split, config, deploy, train, func, data_path, backend, inference\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:27:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:27:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagestetedemoines/000002.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:27:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:27:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagestetedemoines/000007.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:27:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:27:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagestetedemoines/000012.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:27:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:27:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagestetedemoines/000016.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:27:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:27:58\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagestetedemoines/000021.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:27:58\u001b[0m | \u001b[36mautotrain.backend\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:27:58\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m327\u001b[0m - \u001b[1m['python', '-m', 'autotrain.trainers.dreambooth', '--training_config', 'tetedemoines/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:27:58\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m328\u001b[0m - \u001b[1m{'model': 'stabilityai/stable-diffusion-xl-base-1.0', 'vae_model': None, 'revision': None, 'tokenizer': None, 'image_path': 'tetedemoines/autotrain-data', 'class_image_path': None, 'prompt': 'An image of the Tete de Moines cheese', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'tetedemoines', 'seed': 42, 'resolution': 1024, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 1, 'num_steps': 500, 'checkpointing_steps': 100000, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'disable_gradient_checkpointing': False, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': False, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': True, 'mixed_precision': 'fp16', 'token': '*****', 'push_to_hub': True, 'username': 'haroldng', 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 04:28:01\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[33m\u001b[1mFailed to download dataset: 404 Client Error. (Request ID: Root=1-663ae331-55b052ae1a1de2135708b977;e3533600-85e5-44f5-be33-c74cf73ef25c)\n",
            "\n",
            "Repository Not Found for url: https://huggingface.co/api/datasets/tetedemoines/autotrain-data/revision/main.\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are authenticated.\u001b[0m\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "{'rescale_betas_zero_snr', 'clip_sample_range', 'variance_type', 'thresholding', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
            "{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
            "{'dropout', 'attention_type', 'reverse_transformer_layers_per_block'} was not found in config. Values will be initialized to default values.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:28:08\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m931\u001b[0m - \u001b[1m***** Running training *****\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:28:08\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1m  Num examples = 5\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:28:08\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m933\u001b[0m - \u001b[1m  Num batches each epoch = 5\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:28:08\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1m  Num Epochs = 250\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:28:08\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m935\u001b[0m - \u001b[1m  Instantaneous batch size per device = 1\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:28:08\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m936\u001b[0m - \u001b[1m  Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:28:08\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m937\u001b[0m - \u001b[1m  Gradient Accumulation steps = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:28:08\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m938\u001b[0m - \u001b[1m  Total optimization steps = 500\u001b[0m\n",
            "Steps:   0%|                                            | 0/500 [00:00<?, ?it/s]/users/eleves-a/2022/noam-joud-harold.ngoupeyou/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [21:23<00:00,  2.31s/it, loss=0.0743, lr=0.0001]Model weights saved in tetedemoines/pytorch_lora_weights.safetensors\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [21:24<00:00,  2.57s/it, loss=0.0743, lr=0.0001]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:49:32\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1mConverting model to Kohya format...\u001b[0m\n",
            "Upload 2 LFS files:   0%|                                 | 0/2 [00:00<?, ?it/s]\n",
            "pytorch_lora_weights_kohya.safetensors:   0%|       | 0.00/23.5M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   0%|             | 0.00/23.4M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   0%|    | 8.19k/23.4M [00:00<05:32, 70.3kB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:   0%| | 8.19k/23.5M [00:00<06:53, 56.7kB\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:   2%| | 451k/23.5M [00:00<00:12, 1.81MB/\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   7%|â–Ž   | 1.59M/23.4M [00:00<00:03, 6.11MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:   3%| | 705k/23.5M [00:00<00:11, 2.01MB/\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   9%|â–Ž   | 2.12M/23.4M [00:00<00:04, 4.80MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  20%|â–Š   | 4.79M/23.4M [00:00<00:01, 11.1MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  14%|â–| 3.40M/23.5M [00:00<00:02, 8.21MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  34%|â–ˆâ–  | 8.06M/23.4M [00:00<00:00, 17.3MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  18%|â–| 4.29M/23.5M [00:00<00:02, 7.33MB\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  24%|â–| 5.59M/23.5M [00:00<00:02, 8.76MB\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  37%|â–Ž| 8.68M/23.5M [00:00<00:01, 14.7MB\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  66%|â–‹| 15.4M/23.5M [00:01<00:00, 29.2MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  68%|â–ˆâ–ˆâ–‹ | 16.0M/23.4M [00:01<00:00, 16.2MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 23.4M/23.4M [00:01<00:00, 15.2MB/s]\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors: 100%|â–ˆ| 23.5M/23.5M [00:01<00:00, 14.5MB\n",
            "Upload 2 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.01s/it]\n"
          ]
        }
      ],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "project_name = 'tetedemoines' # @param {type:\"string\"}\n",
        "model_name = 'stabilityai/stable-diffusion-xl-base-1.0' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\n",
        "prompt = 'An image of the Tete de Moines cheese' # @param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "hf_username = \"haroldng\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "num_steps = 500 #@param {type:\"number\"}\n",
        "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "gradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "resolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\n",
        "use_8bit_adam = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_xformers = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "mixed_precision = \"fp16\" # @param [\"fp16\", \"bf16\", \"none\"] {type:\"raw\"}\n",
        "train_text_encoder = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "disable_gradient_checkpointing = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"MIXED_PRECISION\"] = str(mixed_precision)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"DISABLE_GRADIENT_CHECKPOINTING\"] = str(disable_gradient_checkpointing)\n",
        "os.environ[\"HF_USERNAME\"] = hf_username\n",
        "\n",
        "\n",
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--image-path imagestetedemoines/ \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "--mixed-precision ${MIXED_PRECISION} \\\n",
        "--username ${HF_USERNAME} \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$DISABLE_GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--disable_gradient-checkpointing\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN}\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:49:43\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m388\u001b[0m - \u001b[1mRunning DreamBooth Training\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 04:49:43\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[33m\u001b[1mParameters not supplied by user and set to default: vae_model\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 04:49:43\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: version, data_path, train_split, func, config, backend, deploy, inference, log, valid_split, train\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:49:43\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:49:43\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagestommedevache/000002.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:49:43\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:49:43\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagestommedevache/000003.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:49:43\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:49:43\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagestommedevache/000005.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:49:43\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:49:43\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagestommedevache/000016.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:49:43\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:49:43\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagestommedevache/000023.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:49:43\u001b[0m | \u001b[36mautotrain.backend\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:49:43\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m327\u001b[0m - \u001b[1m['python', '-m', 'autotrain.trainers.dreambooth', '--training_config', 'tommedevache/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:49:43\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m328\u001b[0m - \u001b[1m{'model': 'stabilityai/stable-diffusion-xl-base-1.0', 'vae_model': None, 'revision': None, 'tokenizer': None, 'image_path': 'tommedevache/autotrain-data', 'class_image_path': None, 'prompt': 'An image of the Tomme de Vache cheese', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'tommedevache', 'seed': 42, 'resolution': 1024, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 1, 'num_steps': 500, 'checkpointing_steps': 100000, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'disable_gradient_checkpointing': False, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': False, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': True, 'mixed_precision': 'fp16', 'token': '*****', 'push_to_hub': True, 'username': 'haroldng', 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 04:49:46\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[33m\u001b[1mFailed to download dataset: 404 Client Error. (Request ID: Root=1-663ae84a-691c718208f7ac79714d92f5;d229c7f3-c072-4cd7-9006-7c4ade615178)\n",
            "\n",
            "Repository Not Found for url: https://huggingface.co/api/datasets/tommedevache/autotrain-data/revision/main.\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are authenticated.\u001b[0m\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "{'clip_sample_range', 'dynamic_thresholding_ratio', 'rescale_betas_zero_snr', 'variance_type', 'thresholding'} was not found in config. Values will be initialized to default values.\n",
            "{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
            "{'attention_type', 'reverse_transformer_layers_per_block', 'dropout'} was not found in config. Values will be initialized to default values.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:49:53\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m931\u001b[0m - \u001b[1m***** Running training *****\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:49:53\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1m  Num examples = 5\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:49:53\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m933\u001b[0m - \u001b[1m  Num batches each epoch = 5\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:49:53\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1m  Num Epochs = 250\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:49:53\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m935\u001b[0m - \u001b[1m  Instantaneous batch size per device = 1\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:49:53\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m936\u001b[0m - \u001b[1m  Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:49:53\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m937\u001b[0m - \u001b[1m  Gradient Accumulation steps = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 04:49:53\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m938\u001b[0m - \u001b[1m  Total optimization steps = 500\u001b[0m\n",
            "Steps:   0%|                                            | 0/500 [00:00<?, ?it/s]/users/eleves-a/2022/noam-joud-harold.ngoupeyou/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [21:06<00:00,  2.27s/it, loss=0.0704, lr=0.0001]Model weights saved in tommedevache/pytorch_lora_weights.safetensors\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [21:06<00:00,  2.53s/it, loss=0.0704, lr=0.0001]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:00\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1mConverting model to Kohya format...\u001b[0m\n",
            "Upload 2 LFS files:   0%|                                 | 0/2 [00:00<?, ?it/s]\n",
            "pytorch_lora_weights.safetensors:   0%|             | 0.00/23.4M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:   0%|       | 0.00/23.5M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:   0%| | 8.19k/23.5M [00:00<05:51, 66.7kB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:   0%|    | 8.19k/23.4M [00:00<06:29, 60.0kB/s]\u001b[A\n",
            "pytorch_lora_weights.safetensors:   2%|     | 393k/23.4M [00:00<00:12, 1.90MB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:  14%|â–| 3.39M/23.5M [00:00<00:01, 15.8MB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:   3%|â–    | 647k/23.4M [00:00<00:12, 1.84MB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:  21%|â–| 4.94M/23.5M [00:00<00:01, 12.1MB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:  15%|â–Œ   | 3.47M/23.4M [00:00<00:02, 8.63MB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:  27%|â–Ž| 6.34M/23.5M [00:00<00:01, 10.7MB\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:  46%|â–| 10.8M/23.5M [00:00<00:00, 19.6MB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:  18%|â–‹   | 4.30M/23.4M [00:00<00:02, 7.15MB/s]\u001b[A\n",
            "pytorch_lora_weights.safetensors:  23%|â–‰   | 5.32M/23.4M [00:00<00:02, 7.31MB/s]\u001b[A\n",
            "pytorch_lora_weights.safetensors:  42%|â–ˆâ–‹  | 9.75M/23.4M [00:00<00:00, 16.5MB/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:  68%|â–‹| 16.0M/23.5M [00:01<00:00, 15.8MB\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:  84%|â–Š| 19.8M/23.5M [00:01<00:00, 19.8MB\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:  97%|â–‰| 22.8M/23.5M [00:01<00:00, 19.0MB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors:  68%|â–ˆâ–ˆâ–‹ | 16.0M/23.4M [00:01<00:00, 16.0MB/s]\u001b[A\n",
            "pytorch_lora_weights.safetensors:  85%|â–ˆâ–ˆâ–ˆâ–| 19.9M/23.4M [00:01<00:00, 19.9MB/s]\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors: 100%|â–ˆ| 23.5M/23.5M [00:01<00:00, 12.1MB\u001b[A\n",
            "pytorch_lora_weights.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 23.4M/23.4M [00:02<00:00, 10.4MB/s]\n",
            "Upload 2 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.28s/it]\n"
          ]
        }
      ],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "project_name = 'tommedevache' # @param {type:\"string\"}\n",
        "model_name = 'stabilityai/stable-diffusion-xl-base-1.0' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\n",
        "prompt = 'An image of the Tomme de Vache cheese' # @param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "hf_username = \"haroldng\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "num_steps = 500 #@param {type:\"number\"}\n",
        "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "gradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "resolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\n",
        "use_8bit_adam = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_xformers = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "mixed_precision = \"fp16\" # @param [\"fp16\", \"bf16\", \"none\"] {type:\"raw\"}\n",
        "train_text_encoder = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "disable_gradient_checkpointing = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"MIXED_PRECISION\"] = str(mixed_precision)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"DISABLE_GRADIENT_CHECKPOINTING\"] = str(disable_gradient_checkpointing)\n",
        "os.environ[\"HF_USERNAME\"] = hf_username\n",
        "\n",
        "\n",
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--image-path imagestommedevache/ \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "--mixed-precision ${MIXED_PRECISION} \\\n",
        "--username ${HF_USERNAME} \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$DISABLE_GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--disable_gradient-checkpointing\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN}\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:10\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m388\u001b[0m - \u001b[1mRunning DreamBooth Training\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 05:11:10\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[33m\u001b[1mParameters not supplied by user and set to default: vae_model\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 05:11:10\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: inference, backend, config, deploy, log, data_path, valid_split, func, train_split, version, train\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:10\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:10\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagespecorino/000001.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:10\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:10\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagespecorino/000008.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:10\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:10\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagespecorino/000012.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:10\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:10\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagespecorino/000017.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:10\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:10\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagespecorino/000019.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:10\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:10\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagespecorino/000020.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:10\u001b[0m | \u001b[36mautotrain.backend\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:10\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m327\u001b[0m - \u001b[1m['python', '-m', 'autotrain.trainers.dreambooth', '--training_config', 'pecorino/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:10\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m328\u001b[0m - \u001b[1m{'model': 'stabilityai/stable-diffusion-xl-base-1.0', 'vae_model': None, 'revision': None, 'tokenizer': None, 'image_path': 'pecorino/autotrain-data', 'class_image_path': None, 'prompt': 'An image of the Pecorino cheese', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'pecorino', 'seed': 42, 'resolution': 1024, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 1, 'num_steps': 500, 'checkpointing_steps': 100000, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'disable_gradient_checkpointing': False, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': False, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': True, 'mixed_precision': 'fp16', 'token': '*****', 'push_to_hub': True, 'username': 'haroldng', 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 05:11:14\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[33m\u001b[1mFailed to download dataset: 404 Client Error. (Request ID: Root=1-663aed52-20deb1af6acce13c04858602;4184134b-6840-4e9e-9dea-8d9ca6d5bc8a)\n",
            "\n",
            "Repository Not Found for url: https://huggingface.co/api/datasets/pecorino/autotrain-data/revision/main.\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are authenticated.\u001b[0m\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "{'variance_type', 'dynamic_thresholding_ratio', 'rescale_betas_zero_snr', 'clip_sample_range', 'thresholding'} was not found in config. Values will be initialized to default values.\n",
            "{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
            "{'dropout', 'reverse_transformer_layers_per_block', 'attention_type'} was not found in config. Values will be initialized to default values.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:20\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m931\u001b[0m - \u001b[1m***** Running training *****\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:20\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1m  Num examples = 6\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:20\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m933\u001b[0m - \u001b[1m  Num batches each epoch = 6\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:20\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1m  Num Epochs = 250\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:20\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m935\u001b[0m - \u001b[1m  Instantaneous batch size per device = 1\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:20\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m936\u001b[0m - \u001b[1m  Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:20\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m937\u001b[0m - \u001b[1m  Gradient Accumulation steps = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:11:20\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m938\u001b[0m - \u001b[1m  Total optimization steps = 500\u001b[0m\n",
            "Steps:   0%|                                            | 0/500 [00:00<?, ?it/s]/users/eleves-a/2022/noam-joud-harold.ngoupeyou/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [25:38<00:00,  2.89s/it, loss=0.0778, lr=0.0001]Model weights saved in pecorino/pytorch_lora_weights.safetensors\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [25:39<00:00,  3.08s/it, loss=0.0778, lr=0.0001]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:37:00\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1mConverting model to Kohya format...\u001b[0m\n",
            "Upload 2 LFS files:   0%|                                 | 0/2 [00:00<?, ?it/s]\n",
            "pytorch_lora_weights_kohya.safetensors:   0%|       | 0.00/23.5M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   0%|             | 0.00/23.4M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:   0%| | 8.19k/23.5M [00:00<07:59, 48.9kB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   0%|    | 8.19k/23.4M [00:00<08:03, 48.4kB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:   9%| | 2.11M/23.5M [00:00<00:02, 8.85MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   2%|     | 434k/23.4M [00:00<00:14, 1.58MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   3%|â–    | 696k/23.4M [00:00<00:11, 1.94MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  14%|â–| 3.19M/23.5M [00:00<00:02, 7.63MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  15%|â–Œ   | 3.45M/23.4M [00:00<00:02, 8.23MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  22%|â–| 5.25M/23.5M [00:00<00:01, 9.77MB\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  48%|â–| 11.2M/23.5M [00:00<00:00, 22.6MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  18%|â–‹   | 4.28M/23.4M [00:00<00:02, 7.16MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  23%|â–‰   | 5.31M/23.4M [00:00<00:02, 7.28MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  38%|â–ˆâ–Œ  | 8.96M/23.4M [00:00<00:01, 14.4MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  68%|â–‹| 16.0M/23.5M [00:01<00:00, 15.9MB\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  88%|â–‰| 20.6M/23.5M [00:01<00:00, 18.6MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  68%|â–ˆâ–ˆâ–‹ | 16.0M/23.4M [00:01<00:00, 16.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  88%|â–ˆâ–ˆâ–ˆâ–Œ| 20.5M/23.4M [00:01<00:00, 18.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors: 100%|â–ˆ| 23.5M/23.5M [00:02<00:00, 11.5MB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 23.4M/23.4M [00:02<00:00, 9.99MB/s]\n",
            "Upload 2 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.32s/it]\n"
          ]
        }
      ],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "project_name = 'pecorino' # @param {type:\"string\"}\n",
        "model_name = 'stabilityai/stable-diffusion-xl-base-1.0' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\n",
        "prompt = 'An image of the Pecorino cheese' # @param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "hf_username = \"haroldng\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "num_steps = 500 #@param {type:\"number\"}\n",
        "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "gradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "resolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\n",
        "use_8bit_adam = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_xformers = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "mixed_precision = \"fp16\" # @param [\"fp16\", \"bf16\", \"none\"] {type:\"raw\"}\n",
        "train_text_encoder = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "disable_gradient_checkpointing = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"MIXED_PRECISION\"] = str(mixed_precision)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"DISABLE_GRADIENT_CHECKPOINTING\"] = str(disable_gradient_checkpointing)\n",
        "os.environ[\"HF_USERNAME\"] = hf_username\n",
        "\n",
        "\n",
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--image-path imagespecorino/ \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "--mixed-precision ${MIXED_PRECISION} \\\n",
        "--username ${HF_USERNAME} \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$DISABLE_GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--disable_gradient-checkpointing\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN}\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:37:10\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m388\u001b[0m - \u001b[1mRunning DreamBooth Training\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 05:37:10\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[33m\u001b[1mParameters not supplied by user and set to default: vae_model\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 05:37:10\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: config, func, backend, version, log, train, inference, deploy, data_path, valid_split, train_split\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:37:10\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:37:10\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesscarmoza/000001.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:37:10\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:37:10\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesscarmoza/000005.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:37:10\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:37:10\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesscarmoza/000017.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:37:10\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:37:10\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesscarmoza/000018.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:37:10\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:37:10\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mimagesscarmoza/000019.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:37:10\u001b[0m | \u001b[36mautotrain.backend\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:37:10\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m327\u001b[0m - \u001b[1m['python', '-m', 'autotrain.trainers.dreambooth', '--training_config', 'scarmoza/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:37:10\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m328\u001b[0m - \u001b[1m{'model': 'stabilityai/stable-diffusion-xl-base-1.0', 'vae_model': None, 'revision': None, 'tokenizer': None, 'image_path': 'scarmoza/autotrain-data', 'class_image_path': None, 'prompt': 'An image of the Scarmoza cheese', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'scarmoza', 'seed': 42, 'resolution': 1024, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 1, 'num_steps': 500, 'checkpointing_steps': 100000, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'disable_gradient_checkpointing': False, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': False, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': True, 'mixed_precision': 'fp16', 'token': '*****', 'push_to_hub': True, 'username': 'haroldng', 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-08 05:37:14\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[33m\u001b[1mFailed to download dataset: 404 Client Error. (Request ID: Root=1-663af36a-4bbc1547263b484b663f0417;35ab17f7-95af-448b-96a6-34ded477354c)\n",
            "\n",
            "Repository Not Found for url: https://huggingface.co/api/datasets/scarmoza/autotrain-data/revision/main.\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are authenticated.\u001b[0m\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "{'rescale_betas_zero_snr', 'dynamic_thresholding_ratio', 'variance_type', 'clip_sample_range', 'thresholding'} was not found in config. Values will be initialized to default values.\n",
            "{'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "{'dropout', 'reverse_transformer_layers_per_block', 'attention_type'} was not found in config. Values will be initialized to default values.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:37:20\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m931\u001b[0m - \u001b[1m***** Running training *****\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:37:20\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1m  Num examples = 5\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:37:20\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m933\u001b[0m - \u001b[1m  Num batches each epoch = 5\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:37:20\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1m  Num Epochs = 250\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:37:20\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m935\u001b[0m - \u001b[1m  Instantaneous batch size per device = 1\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:37:20\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m936\u001b[0m - \u001b[1m  Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:37:20\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m937\u001b[0m - \u001b[1m  Gradient Accumulation steps = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:37:20\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m938\u001b[0m - \u001b[1m  Total optimization steps = 500\u001b[0m\n",
            "Steps:   0%|                                            | 0/500 [00:00<?, ?it/s]/users/eleves-a/2022/noam-joud-harold.ngoupeyou/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [21:12<00:00,  2.28s/it, loss=0.0628, lr=0.0001]Model weights saved in scarmoza/pytorch_lora_weights.safetensors\n",
            "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [21:13<00:00,  2.55s/it, loss=0.0628, lr=0.0001]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-08 05:58:34\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1mConverting model to Kohya format...\u001b[0m\n",
            "Upload 2 LFS files:   0%|                                 | 0/2 [00:00<?, ?it/s]\n",
            "pytorch_lora_weights_kohya.safetensors:   0%|       | 0.00/23.5M [00:00<?, ?B/s]\u001b[A\n",
            "\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:   0%| | 8.19k/23.5M [00:00<05:22, 72.8kB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   0%|    | 8.19k/23.4M [00:00<07:09, 54.4kB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:   2%| | 393k/23.5M [00:00<00:10, 2.12MB/\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   2%|     | 475k/23.4M [00:00<00:14, 1.60MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:   3%| | 647k/23.5M [00:00<00:11, 1.91MB/\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   9%|â–Ž   | 2.14M/23.4M [00:00<00:03, 6.49MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  13%|â–| 3.15M/23.5M [00:00<00:02, 8.67MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  14%|â–Œ   | 3.16M/23.4M [00:00<00:02, 7.62MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  17%|â–| 4.04M/23.5M [00:00<00:02, 7.06MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  17%|â–‹   | 4.06M/23.4M [00:00<00:02, 6.78MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  21%|â–| 5.01M/23.5M [00:00<00:02, 7.49MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  21%|â–Š   | 4.96M/23.4M [00:00<00:02, 6.79MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  34%|â–Ž| 7.95M/23.5M [00:00<00:01, 12.4MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  32%|â–ˆâ–Ž  | 7.52M/23.4M [00:00<00:01, 11.5MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  63%|â–‹| 14.7M/23.5M [00:01<00:00, 26.4MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  60%|â–ˆâ–ˆâ– | 14.1M/23.4M [00:01<00:00, 25.2MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  75%|â–Š| 17.7M/23.5M [00:01<00:00, 18.5MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  72%|â–ˆâ–ˆâ–Š | 16.8M/23.4M [00:01<00:00, 15.6MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  85%|â–Š| 20.0M/23.5M [00:01<00:00, 16.9MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  81%|â–ˆâ–ˆâ–ˆâ–| 18.9M/23.4M [00:01<00:00, 16.1MB/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights_kohya.safetensors:  96%|â–‰| 22.5M/23.5M [00:01<00:00, 17.0MB\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors: 100%|â–ˆ| 23.5M/23.5M [00:02<00:00, 10.8MB\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 23.4M/23.4M [00:02<00:00, 8.90MB/s]\n",
            "Upload 2 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.44s/it]\n"
          ]
        }
      ],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "project_name = 'scarmoza' # @param {type:\"string\"}\n",
        "model_name = 'stabilityai/stable-diffusion-xl-base-1.0' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\n",
        "prompt = 'An image of the Scarmoza cheese' # @param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "hf_username = \"haroldng\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "num_steps = 500 #@param {type:\"number\"}\n",
        "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "gradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "resolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\n",
        "use_8bit_adam = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_xformers = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "mixed_precision = \"fp16\" # @param [\"fp16\", \"bf16\", \"none\"] {type:\"raw\"}\n",
        "train_text_encoder = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "disable_gradient_checkpointing = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"MIXED_PRECISION\"] = str(mixed_precision)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"DISABLE_GRADIENT_CHECKPOINTING\"] = str(disable_gradient_checkpointing)\n",
        "os.environ[\"HF_USERNAME\"] = hf_username\n",
        "\n",
        "\n",
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--image-path imagesscarmoza/ \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "--mixed-precision ${MIXED_PRECISION} \\\n",
        "--username ${HF_USERNAME} \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$DISABLE_GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--disable_gradient-checkpointing\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN}\" )\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
